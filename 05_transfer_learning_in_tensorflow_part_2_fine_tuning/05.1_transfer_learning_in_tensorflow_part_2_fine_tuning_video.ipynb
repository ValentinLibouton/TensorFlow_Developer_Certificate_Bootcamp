{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Transfer Learning with TensorFlow Part 2: Fine-tuning\n",
    "\n",
    "In the previous notebook, we covered transfer learning feature extraction, now it's time to learn about a new kind of transfer learning: fine-tuning."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "114e5636780f503f"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Video NÂ°155: Importing a script full of helper functions (and saving lots of space)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d7125a7a828b8bdc"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Creating helper functions\n",
    "\n",
    "In previous notebooks, we 've created a bunch of helper functions, now we could rewrite them all, however, this is tedious.\n",
    "\n",
    "So, it's a good idea to put functions you'll want to use again in a script you can download and import into your notebooks (or elsewhere).\n",
    "\n",
    "We've done this for some of the functions we've used previously here:\n",
    "\n",
    "```python\n",
    "!wget https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/extras/helper_functions.py\n",
    "```\n",
    "> ðŸ”‘ **Note:** If you're running this notebook in Google Colab, when it times out Colab will delete `helper_function.py`, so you'll have to redownload it if you want access to your helper functions."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "81c99a83815ad406"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import zipfile\n",
    "\n",
    "# Import helper functions we're going to use in this notebook\n",
    "from MachineLearningUtils.training_utilities.model_callbacks import create_tensorboard_callback\n",
    "from MachineLearningUtils.data_visualization.model_learning_curves import plot_loss_curves\n",
    "from MachineLearningUtils.data_visualization.image_visualization import walk_through_dir, display_random_images_from_class\n",
    "from MachineLearningUtils.data_acquisition.data_downloader import download_data, extract_archive_file"
   ],
   "metadata": {
    "collapsed": true
   },
   "id": "initial_id",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Video NÂ°156: Downloading and turning our images into a TensorFlow BatchDataset"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "64a82f6348f4431f"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Let's get some data\n",
    "\n",
    "This time we're going to see how we can use the pretrained models within `tf.keras.applications` and apply them to our own problem (recognizing images of food).\n",
    "\n",
    "link: https://www.tensorflow.org/api_docs/python/tf/keras/applications"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3a1c769d553e2616"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Get 10% of training data of 10 classes of Food101\n",
    "url = \"https://storage.googleapis.com/ztm_tf_course/food_vision/10_food_classes_10_percent.zip\"\n",
    "download_data(url=url,file_path=\"10_food_classes_10_percent.zip\", extract=True)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1df5ca036a49ea0",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Check out how many images and subdirectories are in dataset\n",
    "walk_through_dir(dir_path=\"10_food_classes_10_percent\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5e176d38ab01b179",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Create training and test directory paths\n",
    "train_dir = \"10_food_classes_10_percent/train\"\n",
    "test_dir = \"10_food_classes_10_percent/test\""
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fd50d4f67009e2cf",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Args for image_dataset_from_directory\n",
    "idfd_args={\n",
    "    \"image_size\":(224, 224),\n",
    "    \"label_mode\":\"categorical\",\n",
    "    \"batch_size\":32\n",
    "}"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b617bee7f93077f2",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "train_data_10_percent = tf.keras.preprocessing.image_dataset_from_directory(directory=train_dir,\n",
    "                                                                            **idfd_args)\n",
    "test_data = tf.keras.preprocessing.image_dataset_from_directory(directory=test_dir,\n",
    "                                                                **idfd_args)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ac0780e4313f95a",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "train_data_10_percent"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d568445b5c1cecf7",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Check out the class names of our dataset\n",
    "train_data_10_percent.class_names"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5b425b101fe4fe71",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# See an example of a batch of data\n",
    "for images, labels in train_data_10_percent.take(1):\n",
    "    print(images, labels)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bc660be8c221b2f9",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Video NÂ°157: Discussing the four (actually five) modelling experiments we're running\n",
    "Video NÂ°158: Comparing the TensorFlow Keras Sequential API versus the Functional API\n",
    "NÂ°159: Note: Fixes for EfficientNetB0 model creation + weight loading\n",
    "**Old:**\n",
    "```python\n",
    "base_model = tf.keras.applications.EfficientNetB0(include_top=False)\n",
    "```\n",
    "**New:**\n",
    "```python\n",
    "base_model = tf.keras.applications.efficientnet_v2.EfficientNetV2B0(include_top=False)\n",
    "```\n",
    "Video NÂ°160: Creating our first model with the TensorFlow Keras Functional API"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a72da11707c6f692"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Model 0: Building a transfer learning model using the Keras Functional API\n",
    "\n",
    "The sequential API is straight-forward, it runs our layers in sequential order.\n",
    "\n",
    "But the functional API gives us more flexibility with our models - https://www.tensorflow.org/guide/keras/functional_api"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1fe0974a66c1508f"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# 1. Create base model with tf.keras.applications\n",
    "base_model = tf.keras.applications.efficientnet_v2.EfficientNetV2B0(include_top=False)\n",
    "\n",
    "# 2. Freeze the base model (so the underlying pre-trained patterns aren't updated during training)\n",
    "base_model.trainable = False\n",
    "\n",
    "# 3. Create input into our model\n",
    "inputs = tf.keras.layers.Input(shape=(224, 224, 3), name=\"input_layer\")\n",
    "\n",
    "# 4. If using ResNet50V2 you will need to normalize inputs (you don't have to for EfficientNet(s))\n",
    "# x = tf.keras.layers.experimental.preprocessing.Rescaling(1./255)(inputs)\n",
    "\n",
    "# 5. Pass the inputs to the base_model\n",
    "x = base_model(inputs)\n",
    "print(f\"Shape after passing inputs through base model: {x.shape}\")\n",
    "\n",
    "# 6. Average pool the outputs of the base model (aggregate all the most important information, reduce number of computations)\n",
    "x = tf.keras.layers.GlobalAveragePooling2D(name=\"global_average_pooling_layer\")(x)\n",
    "print(f\"Shape after GlobalAveragePooling2D: {x.shape}\")\n",
    "\n",
    "# 7. Create the output activation layer\n",
    "outputs = tf.keras.layers.Dense(units=10, activation=\"softmax\", name=\"output_layer\")(x)\n",
    "\n",
    "# 8. Combine the inputs with the outputs into a model\n",
    "model_0 = tf.keras.Model(inputs=inputs, outputs=outputs)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "645b938cc247648",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Video NÂ°161: Compiling and fitting our first Functional API model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f9c8e6710d799f07"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# 9. Compile for the model\n",
    "model_0.compile(loss=\"categorical_crossentropy\",\n",
    "                optimizer=tf.keras.optimizers.Adam(),\n",
    "                metrics=[\"accuracy\"])\n",
    "# 10. Fit the model and save its history\n",
    "history_10_percent = model_0.fit(train_data_10_percent,\n",
    "                                 epochs=5,\n",
    "                                 steps_per_epoch=len(train_data_10_percent),\n",
    "                                 validation_data=test_data,\n",
    "                                 validation_steps=int(0.25 * len(test_data)),\n",
    "                                 callbacks=[create_tensorboard_callback(dir_name=\"transfer_learning\",\n",
    "                                                                        experiment_name=\"10_percent_feature_extraction\")])"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "eb80b7f9e6b9621c",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Evaluate on the full test dataset\n",
    "model_0.evaluate(test_data)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1381900379acaab6",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Check the layers in our base model\n",
    "for layer_number, layer in enumerate(base_model.layers):\n",
    "    print(layer_number, layer.name)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "322477961c2e7d6",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# How about we get a summary of the base model?\n",
    "base_model.summary()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "40af8be2ffac0f1",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# How about a summary of our whole model?\n",
    "model_0.summary()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cae029d81ff4c25c",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Check out our model's training curves\n",
    "plot_loss_curves(history=history_10_percent)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "86f67a90d3fdba1c",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Video NÂ°162: Getting a feature vector from our trained model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1e6027f797a0853e"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Getting a feature vector from a trained model\n",
    "\n",
    "Let's demonstrate the Global Average Pooling 2D layer...\n",
    "\n",
    "We have a tensor after our model goes through `base_model` of shape (None, 7, 7, 1280).\n",
    "\n",
    "But then when it passes through GlobalAveragePooling2D, it turns into (None, 1280).\n",
    "\n",
    "Let's use a similar shaped tensor of (1, 4, 4, 3) and then pass it to GlobalAveragePoolin2D."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4ba8c66426e60c4b"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Define the input shape\n",
    "input_shape = (1, 4, 4, 3)\n",
    "\n",
    "# Create a random tensor\n",
    "tf.random.set_seed(42)\n",
    "input_tensor = tf.random.normal(input_shape)\n",
    "print(f\"Random input tensor:\\n {input_tensor}\\n\")\n",
    "\n",
    "# Pass the random tensor through a global average pooling 2D layer\n",
    "global_average_pooled_tensor = tf.keras.layers.GlobalAveragePooling2D()(input_tensor)\n",
    "print(f\"2D global average pooled random tensor:\\n {global_average_pooled_tensor}\\n\")\n",
    "\n",
    "# Check the shape of the different tensors\n",
    "print(f\"Shape of input tensor: {input_tensor.shape}\")\n",
    "print(f\"Shape of Global Average Pooled 2D tensor: {global_average_pooled_tensor.shape}\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9f115ba55f5a5511",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Let's replicate the GlobalAveragePool2D layer\n",
    "tf.reduce_mean(input_tensor=input_tensor, axis=[1,2])"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f921a4f2c5726c3",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "> ðŸ›  **Practice:** Try to do the same with the above two cells but this time use `GlobalMaxPool2D`... and see what happens."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "67aaae7953278f3b"
  },
  {
   "cell_type": "markdown",
   "source": [
    "> ðŸ”‘ **Note:** One of the reasons feature extraction transfer learning is named how it is because what often happens is pretrained model outputs a **feature vector** (a long tensor of numbers which represents the leatned representation of the model on a particular sample, in our case, this is the output of the `tf.keras.layers.GlobalAveragePooling2D()` layer) which can then used to extract patterns out of for our own specific problem. "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d1ad64b61850c37"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Video NÂ°163: Drilling into the concept of a feature vector (a learned representation)\n",
    "Video NÂ°164: Downloading and preparing the data for Model 1(1 percent of training data) "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c9a290c58d9cb660"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Running a series of transfer learning experiments\n",
    "\n",
    "We've seen the incredible  results transfer learning can get with only 10% of the training data, but how does it go with 1% of the training data... How about we set up a bunch of experiments to find out:\n",
    "\n",
    "1. `model_1` - use feature extraction transfer learning with 1% of the training data with data augmentation\n",
    "2. `model_2` - use feature extraction transfer learning with 10% of the training data with data augmentation\n",
    "3. `model_3` - use fine-tuning transfer learning on 10% of the training data with data augmentation\n",
    "4. `model_4` - use fine-tuning transfer learning on 100% of the training data with data augmentation\n",
    "\n",
    "> ðŸ”‘ **Note:** throughout all experiments the same tests dataset will be used to evaluate our model... this ensures consistency across evaluation metrics."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c3e96aec2fef6563"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Getting and preprocessing data for model_1"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c1b54b311125790b"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Download and unzip data - preprocessed from Food101\n",
    "url = \"https://storage.googleapis.com/ztm_tf_course/food_vision/10_food_classes_1_percent.zip\"\n",
    "download_data(url=url, file_path=\"10_food_classes_1_percent.zip\", extract=True)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2984fff9f34ba93a",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Create training and test dir\n",
    "train_dir_1_percent = \"10_food_classes_1_percent/train\"\n",
    "test_dir = \"10_food_classes_1_percent/test\""
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fa18a9662d408da",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# How many images are we working with?\n",
    "walk_through_dir(dir_path=\"10_food_classes_1_percent\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b9ac26bc58259f7b",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Check previously saved arguments\n",
    "idfd_args"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7f03db96ebb93d88",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Setup data loaders\n",
    "train_data_1_percent = tf.keras.preprocessing.image_dataset_from_directory(directory=train_dir_1_percent,\n",
    "                                                                           **idfd_args)\n",
    "\n",
    "test_data = tf.keras.preprocessing.image_dataset_from_directory(directory=test_dir,\n",
    "                                                                **idfd_args)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c706014122881731",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Video NÂ°165: Building a data augmentation layer to use inside our model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9e42b75a146edf46"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Adding data augmentation right into the model\n",
    "\n",
    "To add data augmentation right into our models, we can use the layers inside:\n",
    "* `tf.keras.layers.experimental.preprocessing()`\n",
    "\n",
    "We can see the benefits of doing of doing this within the TensorFlow Data augmentation documentation:\n",
    "https://www.tensorflow.org/tutorials/images/data_augmentation#use_keras_preprocessing_layers\n",
    "\n",
    "Off the top our of heads, after reading the docs, the benefits of using data augmentation inside the model are:\n",
    "* Preprocessing of images (augmenation them) happens on the GPU (much faster) rather than the CPU.\n",
    "* Image data augmenation only happens during training, so we can still export our whole model and use it elsewhere."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8590772176165250"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers.experimental import preprocessing\n",
    "\n",
    "# Create data augmenation stage with horizontal flipping, rotations, zooms, etc\n",
    "data_augmentation = keras.Sequential([\n",
    "    preprocessing.RandomFlip(\"horizontal\"),\n",
    "    preprocessing.RandomRotation(0.2),\n",
    "    preprocessing.RandomZoom(0.2),\n",
    "    preprocessing.RandomHeight(0.2),\n",
    "    preprocessing.RandomWidth(0.2),\n",
    "    # preprocessing.Rescaling(1./255) # Keep for models like ResNet50V2 but EfficientNet's having rescaling built-in\n",
    "], name=\"data_augmentation\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f59f24f409b98a81",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "NÂ°166: Note: Small fix for next video, for images not augmenting\n",
    "**Old:**\n",
    "```python\n",
    "augmented_img = data_augmentation(img)\n",
    "```\n",
    "**New:**\n",
    "```python\n",
    "augmented_img = data_augmentation(img, training=True)\n",
    "```\n",
    "\n",
    "Video NÂ°167: Visualizing what happens when images pass through our data augmentation layer"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4ed14bc16aedbfc"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Visualize our data augmentation layer (and see what happens to our data)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9625446268c63f25"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# View a random image and compare it to its augmented version\n",
    "from pathlib import Path\n",
    "import random\n",
    "from MachineLearningUtils.data_visualization.augmentation_effects import apply_model_and_compare\n",
    "base_dir = Path(\"10_food_classes_1_percent/train\")\n",
    "target_class = random.choice(train_data_1_percent.class_names)\n",
    "target_dir = base_dir / target_class\n",
    "random_image_path = random.choice(list(target_dir.glob('*')))\n",
    "apply_model_and_compare(img_path=random_image_path,\n",
    "                        model=data_augmentation)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f05e15bf1c6683ea",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Video NÂ°168: Building Model 1 (with a data augmentation layer and 1% of training data)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "da946513de0c3417"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Model 1: Feature extraction transfer learning on 1% of the data with data augmentation"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bcfa0f9490bc9e09"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Setup input shape and base model, freezing the base model layers\n",
    "input_shape = (224, 224, 3)\n",
    "base_model = tf.keras.applications.efficientnet_v2.EfficientNetV2B0(include_top=False)\n",
    "base_model.trainable = False\n",
    "\n",
    "# Create input layer\n",
    "inputs = layers.Input(shape=input_shape, name=\"input_layer\")\n",
    "\n",
    "# Add in data augmentation Sequential model as a layer\n",
    "x = data_augmentation(inputs)\n",
    "\n",
    "# Give base_model the inputs (after augmentation) and don't train it\n",
    "x = base_model(x, training=False)\n",
    "\n",
    "# Pool output features of the base model\n",
    "x = layers.GlobalAveragePooling2D(name=\"global_average_pooling_layer\")(x)\n",
    "\n",
    "# Put a dense layer on as the output\n",
    "outputs = layers.Dense(units=10, activation=\"softmax\", name=\"output_layer\")(x)\n",
    "\n",
    "# Make a model using the input and outputs\n",
    "model_1 = keras.Model(inputs, outputs)\n",
    "\n",
    "# Compile the model\n",
    "model_1.compile(loss=\"categorical_crossentropy\",\n",
    "                optimizer=tf.keras.optimizers.Adam(),\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "# Fit the model\n",
    "history_1_percent = model_1.fit(train_data_1_percent,\n",
    "                                epochs=5,\n",
    "                                steps_per_epoch=len(train_data_1_percent),\n",
    "                                validation_data=test_data,\n",
    "                                validation_steps=(0.25 * len(test_data)),\n",
    "                                callbacks=[create_tensorboard_callback(dir_name=\"transfer_learning\",\n",
    "                                                                       experiment_name=\"1_percent_data_aug\")])"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "78cd12c4a1df5d75",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Check out a model summary\n",
    "model_1.summary()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "56a7fb453d3a4e45",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Evaluate on the full test dataset\n",
    "result_1_percent_data_aug = model_1.evaluate(test_data)\n",
    "result_1_percent_data_aug"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d5cecbd1fea9ce27",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# How do the model with 1% of the training data and data augmentation loss curves look?\n",
    "plot_loss_curves(history=history_1_percent)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "dc83ec84d41b9cdc",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Video NÂ°169: Building Model 2 (with a data augmentation layer and 10% of training data)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "11c37e302a393af"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Model 2: feature extraction transfer learning model with 10% of data and data augmentation"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ee3dbd519422b37d"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Get 10% of data\n",
    "url =\"https://storage.googleapis.com/ztm_tf_course/food_vision/10_food_classes_10_percent.zip\"\n",
    "download_data(url=url, file_path=\"10_food_classes_10_percent.zip\", extract=True)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4598af16e2fd3b21",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "train_dir_10_percent = \"10_food_classes_10_percent/train\"\n",
    "test_dir = \"10_food_classes_10_percent/test\""
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6ab9091e4435c6b8",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# How many images are in our directories?\n",
    "walk_through_dir(dir_path=\"10_food_classes_10_percent\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6c206c11c4e60e0f",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Set data inputs\n",
    "print(\"idfd_args:\",idfd_args)\n",
    "train_data_10_percent = tf.keras.preprocessing.image_dataset_from_directory(directory=train_dir_10_percent,\n",
    "                                                                            **idfd_args)\n",
    "\n",
    "test_data = tf.keras.preprocessing.image_dataset_from_directory(directory=test_dir,\n",
    "                                                                **idfd_args)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "df6c2a0d34204d90",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Create model 2 with data augmentation built in\n",
    "from tensorflow.keras.models import Sequential\n",
    "# Build data augmentation layer\n",
    "data_augmentation = Sequential([\n",
    "    preprocessing.RandomFlip(\"horizontal\"),\n",
    "    preprocessing.RandomHeight(0.2),\n",
    "    preprocessing.RandomWidth(0.2),\n",
    "    preprocessing.RandomZoom(0.2),\n",
    "    preprocessing.RandomRotation(0.2),\n",
    "    preprocessing.Rescaling(1/255.) # if you're using a model such as ResNet50V2, you'll need to rescale your data, efficientnet has rescaling built-in\n",
    "], name=\"data_augmentation\")\n",
    "\n",
    "# Setup the input shape to our model\n",
    "input_shape = (224, 224, 3)\n",
    "\n",
    "# Create a frozen base model (also called the backbone)\n",
    "base_model = tf.keras.applications.efficientnet_v2.EfficientNetV2B0(include_top=False)\n",
    "base_model.trainable = False\n",
    "\n",
    "# Create the inputs and outputs (including the layers in between)\n",
    "inputs = layers.Input(shape=input_shape, name=\"input_layer\")\n",
    "x = data_augmentation(inputs) # augment our training images (augmentation doesn't occur on test data)\n",
    "x = base_model(x, training=False) # pass augmented images to base model but keep it in inference mode, this also insures batchnorm layers don't get updated - https://keras.io/guides/transfer_learning/#build-a-model\n",
    "x = layers.GlobalAveragePooling2D(name=\"global_average_pooling_2D\")(x)\n",
    "outputs = layers.Dense(units=10, activation=\"softmax\", name=\"output_layer\")(x)\n",
    "model_2 = tf.keras.Model(inputs, outputs)\n",
    "\n",
    "# Compile\n",
    "model_2.compile(loss=\"categorical_crossentropy\",\n",
    "                optimizer=tf.keras.optimizers.Adam(),\n",
    "                metrics=[\"accuracy\"])"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1fda85b9b4ddcaf8",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "model_2.summary()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2576c2f781ea184f",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Video NÂ°170: Creating a ModelCheckpoint to save our model's weights during training"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f9e5f077d993e9f5"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Creating a ModelCheckpoint callback\n",
    "\n",
    "The ModelCheckpoint callback intermediately saves our model (the full model or just the weights) during training. This is useful so we can come and start where we left off."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ae95429836d8307b"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Set checkpoint path\n",
    "checkpoint_path = \"ten_percent_model_checkpoints_weights/checkpoint.ckpt\"\n",
    "\n",
    "# Create a ModelCheckpoint callback that saves the model's weights only\n",
    "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
    "                                                         save_weights_only=True,\n",
    "                                                         save_best_only=False,\n",
    "                                                         save_freq=\"epoch\", # save every epoch\n",
    "                                                         verbose=1)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9a4e5c698a5e1f49",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Video NÂ°171: Fitting and evaluating Model 2 (and saving its weights using ModelCheckpoint)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3bca6ff7c0580dad"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Fit model 2 passing in the ModelCheckpoint callbacks"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "872ef31ca80ca47"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Fit the model saving checkpoints every epoch\n",
    "initial_epochs = 5\n",
    "history_10_percent_data_aug = model_2.fit(train_data_10_percent,\n",
    "                                          epochs=initial_epochs,\n",
    "                                          validation_data=test_data,\n",
    "                                          validation_steps=int(0.25 * len(test_data)),\n",
    "                                          callbacks=[create_tensorboard_callback(dir_name=\"transfer_learning\",\n",
    "                                                                                 experiment_name=\"10_percent_data_aug\"),\n",
    "                                                     checkpoint_callback])"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "80d70b2431083637",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# What were model_0 results?\n",
    "model_0.evaluate(test_data)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9b07d3371f7c5fb4"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Check model_2 results on all test_data\n",
    "results_10_percent_data_aug = model_2.evaluate(test_data)\n",
    "results_10_percent_data_aug"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2f69c83a17120060",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Plot model loss curves\n",
    "plot_loss_curves(history=history_10_percent_data_aug)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "314eede600779e7a",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Video NÂ°172: Loading and comparing saved weights to our existing trained Model 2"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b1429a29d7e6ff7d"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Loading in checkpointed weights\n",
    "\n",
    "Loading in checkpointed weights returns a model to a specific checkpoint."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ce6353fe067026b4"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Load in saved model weights and evaluate model\n",
    "model_2.load_weights(filepath=checkpoint_path)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9398807b91f697b2",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Evaluate model_2 with loaded weights\n",
    "loaded_weights_model_results = model_2.evaluate(test_data)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ee487f10e8a9a5eb",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# If the results from our previously evaluated model_2 match the loaded weights, everything has worked!\n",
    "results_10_percent_data_aug == loaded_weights_model_results"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1c198092c2b3cf0d",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "results_10_percent_data_aug"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c485b9ff76c3f90d",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "loaded_weights_model_results"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8ca15495e53ffdf",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Check to see if loaded model results are very close to our previous non-loaded model results\n",
    "import numpy as np\n",
    "np.isclose(np.array(results_10_percent_data_aug), np.array(loaded_weights_model_results))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ce21953455c361b3",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Check the difference between the two results\n",
    "print(np.array(results_10_percent_data_aug) - np.array(loaded_weights_model_results))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f35d5340929cf2a5",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Video NÂ°173: Preparing Model 3 (our first fine-tuned model)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e750dccd8100ddfa"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Model 3: Fine-tuning an existing model on 10% of the data\n",
    "\n",
    "> ðŸ”‘ **Note:** Fine-tuning usually works best *after* training a feature extraction model for a few epochs with large amounts of custom data."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f88cf1f8b839eb32"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Layers in loaded model\n",
    "model_2.layers"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7a228948fea23c0"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Are these layers trainable?\n",
    "for layer in model_2.layers:\n",
    "    print(layer, layer.trainable)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ffaf69ca60a4d62a"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
