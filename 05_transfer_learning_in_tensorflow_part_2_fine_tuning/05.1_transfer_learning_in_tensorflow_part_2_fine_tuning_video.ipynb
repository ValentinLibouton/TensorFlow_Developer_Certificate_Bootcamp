{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Transfer Learning with TensorFlow Part 2: Fine-tuning\n",
    "\n",
    "In the previous notebook, we covered transfer learning feature extraction, now it's time to learn about a new kind of transfer learning: fine-tuning."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "114e5636780f503f"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Video NÂ°155: Importing a script full of helper functions (and saving lots of space)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d7125a7a828b8bdc"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Creating helper functions\n",
    "\n",
    "In previous notebooks, we 've created a bunch of helper functions, now we could rewrite them all, however, this is tedious.\n",
    "\n",
    "So, it's a good idea to put functions you'll want to use again in a script you can download and import into your notebooks (or elsewhere).\n",
    "\n",
    "We've done this for some of the functions we've used previously here:\n",
    "\n",
    "```python\n",
    "!wget https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/extras/helper_functions.py\n",
    "```\n",
    "> ðŸ”‘ **Note:** If you're running this notebook in Google Colab, when it times out Colab will delete `helper_function.py`, so you'll have to redownload it if you want access to your helper functions."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "81c99a83815ad406"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-02 13:21:34.453954: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import zipfile\n",
    "\n",
    "# Import helper functions we're going to use in this notebook\n",
    "from MachineLearningUtils.training_utilities.model_callbacks import create_tensorboard_callback\n",
    "from MachineLearningUtils.data_visualization.model_learning_curves import plot_loss_curves\n",
    "from MachineLearningUtils.data_visualization.image_visualization import walk_through_dir, display_random_images_from_class\n",
    "from MachineLearningUtils.data_acquisition.data_downloader import download_data, extract_archive_file"
   ],
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-04-02T11:21:38.996678682Z",
     "start_time": "2024-04-02T11:21:33.595661813Z"
    }
   },
   "id": "initial_id",
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "source": [
    "Video NÂ°156: Downloading and turning our images into a TensorFlow BatchDataset"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "64a82f6348f4431f"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Let's get some data\n",
    "\n",
    "This time we're going to see how we can use the pretrained models within `tf.keras.applications` and apply them to our own problem (recognizing images of food).\n",
    "\n",
    "link: https://www.tensorflow.org/api_docs/python/tf/keras/applications"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3a1c769d553e2616"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The file 10_food_classes_10_percent.zip already exists.\n",
      "Extracting 10_food_classes_10_percent.zip as ZIP...\n",
      "10_food_classes_10_percent.zip has been extracted to current directory.\n"
     ]
    }
   ],
   "source": [
    "# Get 10% of training data of 10 classes of Food101\n",
    "url = \"https://storage.googleapis.com/ztm_tf_course/food_vision/10_food_classes_10_percent.zip\"\n",
    "download_data(url=url,file_path=\"10_food_classes_10_percent.zip\", extract=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-02T11:21:41.570484094Z",
     "start_time": "2024-04-02T11:21:38.996479863Z"
    }
   },
   "id": "1df5ca036a49ea0",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 2 directories and 0 images in '10_food_classes_10_percent'.\n",
      "There are 10 directories and 0 images in '10_food_classes_10_percent/test'.\n",
      "There are 0 directories and 250 images in '10_food_classes_10_percent/test/steak'.\n",
      "There are 0 directories and 250 images in '10_food_classes_10_percent/test/pizza'.\n",
      "There are 0 directories and 250 images in '10_food_classes_10_percent/test/sushi'.\n",
      "There are 0 directories and 250 images in '10_food_classes_10_percent/test/fried_rice'.\n",
      "There are 0 directories and 250 images in '10_food_classes_10_percent/test/chicken_curry'.\n",
      "There are 0 directories and 250 images in '10_food_classes_10_percent/test/grilled_salmon'.\n",
      "There are 0 directories and 250 images in '10_food_classes_10_percent/test/ice_cream'.\n",
      "There are 0 directories and 250 images in '10_food_classes_10_percent/test/hamburger'.\n",
      "There are 0 directories and 250 images in '10_food_classes_10_percent/test/ramen'.\n",
      "There are 0 directories and 250 images in '10_food_classes_10_percent/test/chicken_wings'.\n",
      "There are 10 directories and 0 images in '10_food_classes_10_percent/train'.\n",
      "There are 0 directories and 75 images in '10_food_classes_10_percent/train/steak'.\n",
      "There are 0 directories and 75 images in '10_food_classes_10_percent/train/pizza'.\n",
      "There are 0 directories and 75 images in '10_food_classes_10_percent/train/sushi'.\n",
      "There are 0 directories and 75 images in '10_food_classes_10_percent/train/fried_rice'.\n",
      "There are 0 directories and 75 images in '10_food_classes_10_percent/train/chicken_curry'.\n",
      "There are 0 directories and 75 images in '10_food_classes_10_percent/train/grilled_salmon'.\n",
      "There are 0 directories and 75 images in '10_food_classes_10_percent/train/ice_cream'.\n",
      "There are 0 directories and 75 images in '10_food_classes_10_percent/train/hamburger'.\n",
      "There are 0 directories and 75 images in '10_food_classes_10_percent/train/ramen'.\n",
      "There are 0 directories and 75 images in '10_food_classes_10_percent/train/chicken_wings'.\n"
     ]
    }
   ],
   "source": [
    "# Check out how many images and subdirectories are in dataset\n",
    "walk_through_dir(dir_path=\"10_food_classes_10_percent\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-02T11:21:41.616941465Z",
     "start_time": "2024-04-02T11:21:41.557994936Z"
    }
   },
   "id": "5e176d38ab01b179",
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Create training and test directory paths\n",
    "train_dir = \"10_food_classes_10_percent/train\"\n",
    "test_dir = \"10_food_classes_10_percent/test\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-02T11:21:41.637019488Z",
     "start_time": "2024-04-02T11:21:41.574409175Z"
    }
   },
   "id": "fd50d4f67009e2cf",
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Args for image_dataset_from_directory\n",
    "idfd_args={\n",
    "    \"image_size\":(224, 224),\n",
    "    \"label_mode\":\"categorical\",\n",
    "    \"batch_size\":32\n",
    "}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-02T11:21:41.747589660Z",
     "start_time": "2024-04-02T11:21:41.580230069Z"
    }
   },
   "id": "b617bee7f93077f2",
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Keras cannot be imported. Check that it is installed.",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mImportError\u001B[0m                               Traceback (most recent call last)",
      "File \u001B[0;32m~/miniconda3/envs/ML-env/lib/python3.9/site-packages/tensorflow/python/util/lazy_loader.py:114\u001B[0m, in \u001B[0;36mKerasLazyLoader._initialize\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    113\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 114\u001B[0m   \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mkeras\u001B[39;00m  \u001B[38;5;66;03m# pylint: disable=g-import-not-at-top\u001B[39;00m\n\u001B[1;32m    116\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m keras\u001B[38;5;241m.\u001B[39m__version__\u001B[38;5;241m.\u001B[39mstartswith(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m3.\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n\u001B[1;32m    117\u001B[0m     \u001B[38;5;66;03m# This is the Keras 3.x case.\u001B[39;00m\n",
      "File \u001B[0;32m~/miniconda3/envs/ML-env/lib/python3.9/site-packages/keras/__init__.py:3\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;124;03m\"\"\"AUTOGENERATED. DO NOT EDIT.\"\"\"\u001B[39;00m\n\u001B[0;32m----> 3\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m __internal__\n\u001B[1;32m      4\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m activations\n",
      "File \u001B[0;32m~/miniconda3/envs/ML-env/lib/python3.9/site-packages/keras/__internal__/__init__.py:3\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;124;03m\"\"\"AUTOGENERATED. DO NOT EDIT.\"\"\"\u001B[39;00m\n\u001B[0;32m----> 3\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m__internal__\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m backend\n\u001B[1;32m      4\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m__internal__\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m layers\n",
      "File \u001B[0;32m~/miniconda3/envs/ML-env/lib/python3.9/site-packages/keras/__internal__/backend/__init__.py:3\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;124;03m\"\"\"AUTOGENERATED. DO NOT EDIT.\"\"\"\u001B[39;00m\n\u001B[0;32m----> 3\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msrc\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mbackend\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m _initialize_variables \u001B[38;5;28;01mas\u001B[39;00m initialize_variables\n\u001B[1;32m      4\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msrc\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mbackend\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m track_variable\n",
      "File \u001B[0;32m~/miniconda3/envs/ML-env/lib/python3.9/site-packages/keras/src/__init__.py:21\u001B[0m\n\u001B[1;32m     15\u001B[0m \u001B[38;5;124;03m\"\"\"Implementation of the Keras API, the high-level API of TensorFlow.\u001B[39;00m\n\u001B[1;32m     16\u001B[0m \n\u001B[1;32m     17\u001B[0m \u001B[38;5;124;03mDetailed documentation and user guides are available at\u001B[39;00m\n\u001B[1;32m     18\u001B[0m \u001B[38;5;124;03m[keras.io](https://keras.io).\u001B[39;00m\n\u001B[1;32m     19\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m---> 21\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msrc\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m applications\n\u001B[1;32m     22\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msrc\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m distribute\n",
      "File \u001B[0;32m~/miniconda3/envs/ML-env/lib/python3.9/site-packages/keras/src/applications/__init__.py:18\u001B[0m\n\u001B[1;32m     15\u001B[0m \u001B[38;5;124;03m\"\"\"Keras Applications are premade architectures with pre-trained weights.\"\"\"\u001B[39;00m\n\u001B[0;32m---> 18\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msrc\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mapplications\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mconvnext\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m ConvNeXtBase\n\u001B[1;32m     19\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msrc\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mapplications\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mconvnext\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m ConvNeXtLarge\n",
      "File \u001B[0;32m~/miniconda3/envs/ML-env/lib/python3.9/site-packages/keras/src/applications/convnext.py:28\u001B[0m\n\u001B[1;32m     26\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcompat\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mv2\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mtf\u001B[39;00m\n\u001B[0;32m---> 28\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msrc\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m backend\n\u001B[1;32m     29\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msrc\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m initializers\n",
      "File \u001B[0;32m~/miniconda3/envs/ML-env/lib/python3.9/site-packages/keras/src/backend/__init__.py:9\u001B[0m\n\u001B[1;32m      7\u001B[0m     \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mtorch\u001B[39;00m\n\u001B[0;32m----> 9\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msrc\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mbackend\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcommon\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mdtypes\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m result_type\n\u001B[1;32m     10\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msrc\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mbackend\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcommon\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mkeras_tensor\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m KerasTensor\n",
      "File \u001B[0;32m~/miniconda3/envs/ML-env/lib/python3.9/site-packages/keras/src/backend/common/__init__.py:2\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msrc\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mbackend\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcommon\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m backend_utils\n\u001B[0;32m----> 2\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msrc\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mbackend\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcommon\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mdtypes\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m result_type\n\u001B[1;32m      3\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msrc\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mbackend\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcommon\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mvariables\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m AutocastScope\n",
      "File \u001B[0;32m~/miniconda3/envs/ML-env/lib/python3.9/site-packages/keras/src/backend/common/dtypes.py:5\u001B[0m\n\u001B[1;32m      4\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msrc\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mapi_export\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m keras_export\n\u001B[0;32m----> 5\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msrc\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mbackend\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcommon\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mvariables\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m ALLOWED_DTYPES\n\u001B[1;32m      6\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msrc\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mbackend\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcommon\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mvariables\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m standardize_dtype\n",
      "File \u001B[0;32m~/miniconda3/envs/ML-env/lib/python3.9/site-packages/keras/src/backend/common/variables.py:9\u001B[0m\n\u001B[1;32m      8\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msrc\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mbackend\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcommon\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mstateless_scope\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m in_stateless_scope\n\u001B[0;32m----> 9\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msrc\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mutils\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mmodule_utils\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m tensorflow \u001B[38;5;28;01mas\u001B[39;00m tf\n\u001B[1;32m     10\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msrc\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mutils\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mnaming\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m auto_name\n",
      "File \u001B[0;32m~/miniconda3/envs/ML-env/lib/python3.9/site-packages/keras/src/utils/__init__.py:53\u001B[0m\n\u001B[1;32m     52\u001B[0m \u001B[38;5;66;03m# Preprocessing utils\u001B[39;00m\n\u001B[0;32m---> 53\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msrc\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mutils\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mfeature_space\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m FeatureSpace\n\u001B[1;32m     55\u001B[0m \u001B[38;5;66;03m# Internal\u001B[39;00m\n",
      "File \u001B[0;32m~/miniconda3/envs/ML-env/lib/python3.9/site-packages/keras/src/utils/feature_space.py:20\u001B[0m\n\u001B[1;32m     19\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msrc\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m backend\n\u001B[0;32m---> 20\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msrc\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mengine\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m base_layer\n\u001B[1;32m     21\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msrc\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msaving\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m saving_lib\n",
      "File \u001B[0;32m~/miniconda3/envs/ML-env/lib/python3.9/site-packages/keras/src/engine/base_layer.py:32\u001B[0m\n\u001B[1;32m     31\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msrc\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m backend\n\u001B[0;32m---> 32\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msrc\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m constraints\n\u001B[1;32m     33\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msrc\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m initializers\n",
      "File \u001B[0;32m~/miniconda3/envs/ML-env/lib/python3.9/site-packages/keras/src/constraints/__init__.py:4\u001B[0m\n\u001B[1;32m      3\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msrc\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mapi_export\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m keras_export\n\u001B[0;32m----> 4\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msrc\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mconstraints\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mconstraints\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Constraint\n\u001B[1;32m      5\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msrc\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mconstraints\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mconstraints\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m MaxNorm\n",
      "File \u001B[0;32m~/miniconda3/envs/ML-env/lib/python3.9/site-packages/keras/src/constraints/constraints.py:2\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msrc\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m backend\n\u001B[0;32m----> 2\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msrc\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m ops\n\u001B[1;32m      3\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msrc\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mapi_export\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m keras_export\n",
      "File \u001B[0;32m~/miniconda3/envs/ML-env/lib/python3.9/site-packages/keras/src/ops/__init__.py:5\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# from keras.src.ops.numpy import Matmul, matmul\u001B[39;00m\n\u001B[1;32m      2\u001B[0m \u001B[38;5;66;03m# from keras.src.ops.numpy import Add, add\u001B[39;00m\n\u001B[1;32m      3\u001B[0m \u001B[38;5;66;03m# from keras.src.ops.numpy import Multiply, multiply\u001B[39;00m\n\u001B[0;32m----> 5\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msrc\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mbackend\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m cast\n\u001B[1;32m      6\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msrc\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mbackend\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m cond\n",
      "\u001B[0;31mImportError\u001B[0m: cannot import name 'cast' from partially initialized module 'keras.src.backend' (most likely due to a circular import) (/home/wm18vw/miniconda3/envs/ML-env/lib/python3.9/site-packages/keras/src/backend/__init__.py)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[0;31mImportError\u001B[0m                               Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[7], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mtf\u001B[39;00m\n\u001B[0;32m----> 2\u001B[0m train_data_10_percent \u001B[38;5;241m=\u001B[39m \u001B[43mtf\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mkeras\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpreprocessing\u001B[49m\u001B[38;5;241m.\u001B[39mimage_dataset_from_directory(directory\u001B[38;5;241m=\u001B[39mtrain_dir,\n\u001B[1;32m      3\u001B[0m                                                                             \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39midfd_args)\n\u001B[1;32m      4\u001B[0m test_data \u001B[38;5;241m=\u001B[39m tf\u001B[38;5;241m.\u001B[39mkeras\u001B[38;5;241m.\u001B[39mpreprocessing\u001B[38;5;241m.\u001B[39mimage_dataset_from_directory(directory\u001B[38;5;241m=\u001B[39mtest_dir,\n\u001B[1;32m      5\u001B[0m                                                                 \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39midfd_args)\n",
      "File \u001B[0;32m~/miniconda3/envs/ML-env/lib/python3.9/site-packages/tensorflow/python/util/lazy_loader.py:146\u001B[0m, in \u001B[0;36mKerasLazyLoader.__getattr__\u001B[0;34m(self, item)\u001B[0m\n\u001B[1;32m    144\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28msuper\u001B[39m(types\u001B[38;5;241m.\u001B[39mModuleType, \u001B[38;5;28mself\u001B[39m)\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__getattribute__\u001B[39m(item)\n\u001B[1;32m    145\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_initialized:\n\u001B[0;32m--> 146\u001B[0m   \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_initialize\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    147\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_keras_version \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mkeras_3\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[1;32m    148\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_mode \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mv1\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01mand\u001B[39;00m\n\u001B[1;32m    149\u001B[0m       \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_submodule \u001B[38;5;129;01mand\u001B[39;00m\n\u001B[1;32m    150\u001B[0m       item\u001B[38;5;241m.\u001B[39mstartswith(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcompat.v1.\u001B[39m\u001B[38;5;124m\"\u001B[39m)):\n",
      "File \u001B[0;32m~/miniconda3/envs/ML-env/lib/python3.9/site-packages/tensorflow/python/util/lazy_loader.py:128\u001B[0m, in \u001B[0;36mKerasLazyLoader._initialize\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    126\u001B[0m         package_name \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mkeras.api._v2.keras\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    127\u001B[0m   \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mImportError\u001B[39;00m:\n\u001B[0;32m--> 128\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mImportError\u001B[39;00m(  \u001B[38;5;66;03m# pylint: disable=raise-missing-from\u001B[39;00m\n\u001B[1;32m    129\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mKeras cannot be imported. Check that it is installed.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    130\u001B[0m     )\n\u001B[1;32m    132\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_keras_version \u001B[38;5;241m=\u001B[39m keras_version\n\u001B[1;32m    133\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m keras_version \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "\u001B[0;31mImportError\u001B[0m: Keras cannot be imported. Check that it is installed."
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "train_data_10_percent = tf.keras.preprocessing.image_dataset_from_directory(directory=train_dir,\n",
    "                                                                            **idfd_args)\n",
    "test_data = tf.keras.preprocessing.image_dataset_from_directory(directory=test_dir,\n",
    "                                                                **idfd_args)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-02T11:21:42.748011650Z",
     "start_time": "2024-04-02T11:21:41.596566938Z"
    }
   },
   "id": "ac0780e4313f95a",
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "train_data_10_percent"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-02T11:21:42.903454129Z",
     "start_time": "2024-04-02T11:21:42.751453160Z"
    }
   },
   "id": "d568445b5c1cecf7",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Check out the class names of our dataset\n",
    "train_data_10_percent.class_names"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-04-02T11:21:42.796203040Z"
    }
   },
   "id": "5b425b101fe4fe71",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# See an example of a batch of data\n",
    "for images, labels in train_data_10_percent.take(1):\n",
    "    print(images, labels)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-04-02T11:21:42.796729813Z"
    }
   },
   "id": "bc660be8c221b2f9",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Video NÂ°157: Discussing the four (actually five) modelling experiments we're running\n",
    "Video NÂ°158: Comparing the TensorFlow Keras Sequential API versus the Functional API\n",
    "NÂ°159: Note: Fixes for EfficientNetB0 model creation + weight loading\n",
    "**Old:**\n",
    "```python\n",
    "base_model = tf.keras.applications.EfficientNetB0(include_top=False)\n",
    "```\n",
    "**New:**\n",
    "```python\n",
    "base_model = tf.keras.applications.efficientnet_v2.EfficientNetV2B0(include_top=False)\n",
    "```\n",
    "Video NÂ°160: Creating our first model with the TensorFlow Keras Functional API"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a72da11707c6f692"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Model 0: Building a transfer learning model using the Keras Functional API\n",
    "\n",
    "The sequential API is straight-forward, it runs our layers in sequential order.\n",
    "\n",
    "But the functional API gives us more flexibility with our models - https://www.tensorflow.org/guide/keras/functional_api"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1fe0974a66c1508f"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# 1. Create base model with tf.keras.applications\n",
    "base_model = tf.keras.applications.efficientnet_v2.EfficientNetV2B0(include_top=False)\n",
    "\n",
    "# 2. Freeze the base model (so the underlying pre-trained patterns aren't updated during training)\n",
    "base_model.trainable = False\n",
    "\n",
    "# 3. Create input into our model\n",
    "inputs = tf.keras.layers.Input(shape=(224, 224, 3), name=\"input_layer\")\n",
    "\n",
    "# 4. If using ResNet50V2 you will need to normalize inputs (you don't have to for EfficientNet(s))\n",
    "# x = tf.keras.layers.experimental.preprocessing.Rescaling(1./255)(inputs)\n",
    "\n",
    "# 5. Pass the inputs to the base_model\n",
    "x = base_model(inputs)\n",
    "print(f\"Shape after passing inputs through base model: {x.shape}\")\n",
    "\n",
    "# 6. Average pool the outputs of the base model (aggregate all the most important information, reduce number of computations)\n",
    "x = tf.keras.layers.GlobalAveragePooling2D(name=\"global_average_pooling_layer\")(x)\n",
    "print(f\"Shape after GlobalAveragePooling2D: {x.shape}\")\n",
    "\n",
    "# 7. Create the output activation layer\n",
    "outputs = tf.keras.layers.Dense(units=10, activation=\"softmax\", name=\"output_layer\")(x)\n",
    "\n",
    "# 8. Combine the inputs with the outputs into a model\n",
    "model_0 = tf.keras.Model(inputs=inputs, outputs=outputs)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-04-02T11:21:42.797132029Z"
    }
   },
   "id": "645b938cc247648",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Video NÂ°161: Compiling and fitting our first Functional API model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f9c8e6710d799f07"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# 9. Compile for the model\n",
    "model_0.compile(loss=\"categorical_crossentropy\",\n",
    "                optimizer=tf.keras.optimizers.Adam(),\n",
    "                metrics=[\"accuracy\"])\n",
    "# 10. Fit the model and save its history\n",
    "history_10_percent = model_0.fit(train_data_10_percent,\n",
    "                                 epochs=5,\n",
    "                                 steps_per_epoch=len(train_data_10_percent),\n",
    "                                 validation_data=test_data,\n",
    "                                 validation_steps=int(0.25 * len(test_data)),\n",
    "                                 callbacks=[create_tensorboard_callback(dir_name=\"transfer_learning\",\n",
    "                                                                        experiment_name=\"10_percent_feature_extraction\")])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-04-02T11:21:42.797418589Z"
    }
   },
   "id": "eb80b7f9e6b9621c",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Evaluate on the full test dataset\n",
    "model_0.evaluate(test_data)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-04-02T11:21:42.797745378Z"
    }
   },
   "id": "1381900379acaab6",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Check the layers in our base model\n",
    "for layer_number, layer in enumerate(base_model.layers):\n",
    "    print(layer_number, layer.name)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-04-02T11:21:42.798066700Z"
    }
   },
   "id": "322477961c2e7d6",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# How about we get a summary of the base model?\n",
    "base_model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-04-02T11:21:42.799240282Z"
    }
   },
   "id": "40af8be2ffac0f1",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# How about a summary of our whole model?\n",
    "model_0.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-04-02T11:21:42.799624134Z"
    }
   },
   "id": "cae029d81ff4c25c",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Check out our model's training curves\n",
    "plot_loss_curves(history=history_10_percent)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-04-02T11:21:42.799887553Z"
    }
   },
   "id": "86f67a90d3fdba1c",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Video NÂ°162: Getting a feature vector from our trained model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1e6027f797a0853e"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Getting a feature vector from a trained model\n",
    "\n",
    "Let's demonstrate the Global Average Pooling 2D layer...\n",
    "\n",
    "We have a tensor after our model goes through `base_model` of shape (None, 7, 7, 1280).\n",
    "\n",
    "But then when it passes through GlobalAveragePooling2D, it turns into (None, 1280).\n",
    "\n",
    "Let's use a similar shaped tensor of (1, 4, 4, 3) and then pass it to GlobalAveragePoolin2D."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4ba8c66426e60c4b"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Define the input shape\n",
    "input_shape = (1, 4, 4, 3)\n",
    "\n",
    "# Create a random tensor\n",
    "tf.random.set_seed(42)\n",
    "input_tensor = tf.random.normal(input_shape)\n",
    "print(f\"Random input tensor:\\n {input_tensor}\\n\")\n",
    "\n",
    "# Pass the random tensor through a global average pooling 2D layer\n",
    "global_average_pooled_tensor = tf.keras.layers.GlobalAveragePooling2D()(input_tensor)\n",
    "print(f\"2D global average pooled random tensor:\\n {global_average_pooled_tensor}\\n\")\n",
    "\n",
    "# Check the shape of the different tensors\n",
    "print(f\"Shape of input tensor: {input_tensor.shape}\")\n",
    "print(f\"Shape of Global Average Pooled 2D tensor: {global_average_pooled_tensor.shape}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-04-02T11:21:42.800188170Z"
    }
   },
   "id": "9f115ba55f5a5511",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Let's replicate the GlobalAveragePool2D layer\n",
    "tf.reduce_mean(input_tensor=input_tensor, axis=[1,2])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-04-02T11:21:42.800401179Z"
    }
   },
   "id": "f921a4f2c5726c3",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "> ðŸ›  **Practice:** Try to do the same with the above two cells but this time use `GlobalMaxPool2D`... and see what happens."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "67aaae7953278f3b"
  },
  {
   "cell_type": "markdown",
   "source": [
    "> ðŸ”‘ **Note:** One of the reasons feature extraction transfer learning is named how it is because what often happens is pretrained model outputs a **feature vector** (a long tensor of numbers which represents the leatned representation of the model on a particular sample, in our case, this is the output of the `tf.keras.layers.GlobalAveragePooling2D()` layer) which can then used to extract patterns out of for our own specific problem. "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d1ad64b61850c37"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Video NÂ°163: Drilling into the concept of a feature vector (a learned representation)\n",
    "Video NÂ°164: Downloading and preparing the data for Model 1(1 percent of training data) "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c9a290c58d9cb660"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Running a series of transfer learning experiments\n",
    "\n",
    "We've seen the incredible  results transfer learning can get with only 10% of the training data, but how does it go with 1% of the training data... How about we set up a bunch of experiments to find out:\n",
    "\n",
    "1. `model_1` - use feature extraction transfer learning with 1% of the training data with data augmentation\n",
    "2. `model_2` - use feature extraction transfer learning with 10% of the training data with data augmentation\n",
    "3. `model_3` - use fine-tuning transfer learning on 10% of the training data with data augmentation\n",
    "4. `model_4` - use fine-tuning transfer learning on 100% of the training data with data augmentation\n",
    "\n",
    "> ðŸ”‘ **Note:** throughout all experiments the same tests dataset will be used to evaluate our model... this ensures consistency across evaluation metrics."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c3e96aec2fef6563"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Getting and preprocessing data for model_1"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c1b54b311125790b"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Download and unzip data - preprocessed from Food101\n",
    "url = \"https://storage.googleapis.com/ztm_tf_course/food_vision/10_food_classes_1_percent.zip\"\n",
    "download_data(url=url, file_path=\"10_food_classes_1_percent.zip\", extract=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-04-02T11:21:42.800587887Z"
    }
   },
   "id": "2984fff9f34ba93a",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Create training and test dir\n",
    "train_dir_1_percent = \"10_food_classes_1_percent/train\"\n",
    "test_dir = \"10_food_classes_1_percent/test\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-04-02T11:21:42.800806212Z"
    }
   },
   "id": "fa18a9662d408da",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# How many images are we working with?\n",
    "walk_through_dir(dir_path=\"10_food_classes_1_percent\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-04-02T11:21:42.801304009Z"
    }
   },
   "id": "b9ac26bc58259f7b",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Check previously saved arguments\n",
    "idfd_args"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-04-02T11:21:42.804945292Z"
    }
   },
   "id": "7f03db96ebb93d88",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Setup data loaders\n",
    "train_data_1_percent = tf.keras.preprocessing.image_dataset_from_directory(directory=train_dir_1_percent,\n",
    "                                                                           **idfd_args)\n",
    "\n",
    "test_data = tf.keras.preprocessing.image_dataset_from_directory(directory=test_dir,\n",
    "                                                                **idfd_args)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-04-02T11:21:42.810948713Z"
    }
   },
   "id": "c706014122881731",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Video NÂ°165: Building a data augmentation layer to use inside our model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9e42b75a146edf46"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Adding data augmentation right into the model\n",
    "\n",
    "To add data augmentation right into our models, we can use the layers inside:\n",
    "* `tf.keras.layers.experimental.preprocessing()`\n",
    "\n",
    "We can see the benefits of doing of doing this within the TensorFlow Data augmentation documentation:\n",
    "https://www.tensorflow.org/tutorials/images/data_augmentation#use_keras_preprocessing_layers\n",
    "\n",
    "Off the top our of heads, after reading the docs, the benefits of using data augmentation inside the model are:\n",
    "* Preprocessing of images (augmenation them) happens on the GPU (much faster) rather than the CPU.\n",
    "* Image data augmenation only happens during training, so we can still export our whole model and use it elsewhere."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8590772176165250"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers.experimental import preprocessing\n",
    "\n",
    "# Create data augmenation stage with horizontal flipping, rotations, zooms, etc\n",
    "data_augmentation = keras.Sequential([\n",
    "    preprocessing.RandomFlip(\"horizontal\"),\n",
    "    preprocessing.RandomRotation(0.2),\n",
    "    preprocessing.RandomZoom(0.2),\n",
    "    preprocessing.RandomHeight(0.2),\n",
    "    preprocessing.RandomWidth(0.2),\n",
    "    # preprocessing.Rescaling(1./255) # Keep for models like ResNet50V2 but EfficientNet's having rescaling built-in\n",
    "], name=\"data_augmentation\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-04-02T11:21:42.815315932Z"
    }
   },
   "id": "f59f24f409b98a81",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "NÂ°166: Note: Small fix for next video, for images not augmenting\n",
    "**Old:**\n",
    "```python\n",
    "augmented_img = data_augmentation(img)\n",
    "```\n",
    "**New:**\n",
    "```python\n",
    "augmented_img = data_augmentation(img, training=True)\n",
    "```\n",
    "\n",
    "Video NÂ°167: Visualizing what happens when images pass through our data augmentation layer"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4ed14bc16aedbfc"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Visualize our data augmentation layer (and see what happens to our data)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9625446268c63f25"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# View a random image and compare it to its augmented version\n",
    "from pathlib import Path\n",
    "import random\n",
    "from MachineLearningUtils.data_visualization.augmentation_effects import apply_model_and_compare\n",
    "base_dir = Path(\"10_food_classes_1_percent/train\")\n",
    "target_class = random.choice(train_data_1_percent.class_names)\n",
    "target_dir = base_dir / target_class\n",
    "random_image_path = random.choice(list(target_dir.glob('*')))\n",
    "apply_model_and_compare(img_path=random_image_path,\n",
    "                        model=data_augmentation)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-04-02T11:21:42.856181157Z"
    }
   },
   "id": "f05e15bf1c6683ea",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Video NÂ°168: Building Model 1 (with a data augmentation layer and 1% of training data)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "da946513de0c3417"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Model 1: Feature extraction transfer learning on 1% of the data with data augmentation"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bcfa0f9490bc9e09"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Setup input shape and base model, freezing the base model layers\n",
    "input_shape = (224, 224, 3)\n",
    "base_model = tf.keras.applications.efficientnet_v2.EfficientNetV2B0(include_top=False)\n",
    "base_model.trainable = False\n",
    "\n",
    "# Create input layer\n",
    "inputs = layers.Input(shape=input_shape, name=\"input_layer\")\n",
    "\n",
    "# Add in data augmentation Sequential model as a layer\n",
    "x = data_augmentation(inputs)\n",
    "\n",
    "# Give base_model the inputs (after augmentation) and don't train it\n",
    "x = base_model(x, training=False)\n",
    "\n",
    "# Pool output features of the base model\n",
    "x = layers.GlobalAveragePooling2D(name=\"global_average_pooling_layer\")(x)\n",
    "\n",
    "# Put a dense layer on as the output\n",
    "outputs = layers.Dense(units=10, activation=\"softmax\", name=\"output_layer\")(x)\n",
    "\n",
    "# Make a model using the input and outputs\n",
    "model_1 = keras.Model(inputs, outputs)\n",
    "\n",
    "# Compile the model\n",
    "model_1.compile(loss=\"categorical_crossentropy\",\n",
    "                optimizer=tf.keras.optimizers.Adam(),\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "# Fit the model\n",
    "history_1_percent = model_1.fit(train_data_1_percent,\n",
    "                                epochs=5,\n",
    "                                steps_per_epoch=len(train_data_1_percent),\n",
    "                                validation_data=test_data,\n",
    "                                validation_steps=(0.25 * len(test_data)),\n",
    "                                callbacks=[create_tensorboard_callback(dir_name=\"transfer_learning\",\n",
    "                                                                       experiment_name=\"1_percent_data_aug\")])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-04-02T11:21:42.856502890Z"
    }
   },
   "id": "78cd12c4a1df5d75",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Check out a model summary\n",
    "model_1.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-04-02T11:21:42.856725101Z"
    }
   },
   "id": "56a7fb453d3a4e45",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Evaluate on the full test dataset\n",
    "result_1_percent_data_aug = model_1.evaluate(test_data)\n",
    "result_1_percent_data_aug"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-04-02T11:21:42.856976394Z"
    }
   },
   "id": "d5cecbd1fea9ce27",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# How do the model with 1% of the training data and data augmentation loss curves look?\n",
    "plot_loss_curves(history=history_1_percent)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-04-02T11:21:42.857191045Z"
    }
   },
   "id": "dc83ec84d41b9cdc",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Video NÂ°169: Building Model 2 (with a data augmentation layer and 10% of training data)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "11c37e302a393af"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Model 2: feature extraction transfer learning model with 10% of data and data augmentation"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ee3dbd519422b37d"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Get 10% of data\n",
    "url =\"https://storage.googleapis.com/ztm_tf_course/food_vision/10_food_classes_10_percent.zip\"\n",
    "download_data(url=url, file_path=\"10_food_classes_10_percent.zip\", extract=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-04-02T11:21:42.857405387Z"
    }
   },
   "id": "4598af16e2fd3b21",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "train_dir_10_percent = \"10_food_classes_10_percent/train\"\n",
    "test_dir = \"10_food_classes_10_percent/test\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-04-02T11:21:42.857602619Z"
    }
   },
   "id": "6ab9091e4435c6b8",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# How many images are in our directories?\n",
    "walk_through_dir(dir_path=\"10_food_classes_10_percent\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-04-02T11:21:42.857827891Z"
    }
   },
   "id": "6c206c11c4e60e0f",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Set data inputs\n",
    "print(\"idfd_args:\",idfd_args)\n",
    "train_data_10_percent = tf.keras.preprocessing.image_dataset_from_directory(directory=train_dir_10_percent,\n",
    "                                                                            **idfd_args)\n",
    "\n",
    "test_data = tf.keras.preprocessing.image_dataset_from_directory(directory=test_dir,\n",
    "                                                                **idfd_args)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-04-02T11:21:42.858029497Z"
    }
   },
   "id": "df6c2a0d34204d90",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Create model 2 with data augmentation built in\n",
    "from tensorflow.keras.models import Sequential\n",
    "# Build data augmentation layer\n",
    "data_augmentation = Sequential([\n",
    "    preprocessing.RandomFlip(\"horizontal\"),\n",
    "    preprocessing.RandomHeight(0.2),\n",
    "    preprocessing.RandomWidth(0.2),\n",
    "    preprocessing.RandomZoom(0.2),\n",
    "    preprocessing.RandomRotation(0.2),\n",
    "    preprocessing.Rescaling(1/255.) # if you're using a model such as ResNet50V2, you'll need to rescale your data, efficientnet has rescaling built-in\n",
    "], name=\"data_augmentation\")\n",
    "\n",
    "# Setup the input shape to our model\n",
    "input_shape = (224, 224, 3)\n",
    "\n",
    "# Create a frozen base model (also called the backbone)\n",
    "base_model = tf.keras.applications.efficientnet_v2.EfficientNetV2B0(include_top=False)\n",
    "base_model.trainable = False\n",
    "\n",
    "# Create the inputs and outputs (including the layers in between)\n",
    "inputs = layers.Input(shape=input_shape, name=\"input_layer\")\n",
    "x = data_augmentation(inputs) # augment our training images (augmentation doesn't occur on test data)\n",
    "x = base_model(x, training=False) # pass augmented images to base model but keep it in inference mode, this also insures batchnorm layers don't get updated - https://keras.io/guides/transfer_learning/#build-a-model\n",
    "x = layers.GlobalAveragePooling2D(name=\"global_average_pooling_2D\")(x)\n",
    "outputs = layers.Dense(units=10, activation=\"softmax\", name=\"output_layer\")(x)\n",
    "model_2 = tf.keras.Model(inputs, outputs)\n",
    "\n",
    "# Compile\n",
    "model_2.compile(loss=\"categorical_crossentropy\",\n",
    "                optimizer=tf.keras.optimizers.Adam(),\n",
    "                metrics=[\"accuracy\"])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-04-02T11:21:42.858246102Z"
    }
   },
   "id": "1fda85b9b4ddcaf8",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "model_2.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-04-02T11:21:42.858434527Z"
    }
   },
   "id": "2576c2f781ea184f",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Video NÂ°170: Creating a ModelCheckpoint to save our model's weights during training"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f9e5f077d993e9f5"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Creating a ModelCheckpoint callback\n",
    "\n",
    "The ModelCheckpoint callback intermediately saves our model (the full model or just the weights) during training. This is useful so we can come and start where we left off."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ae95429836d8307b"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Set checkpoint path\n",
    "checkpoint_path = \"ten_percent_model_checkpoints_weights/checkpoint.ckpt\"\n",
    "\n",
    "# Create a ModelCheckpoint callback that saves the model's weights only\n",
    "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
    "                                                         save_weights_only=True,\n",
    "                                                         save_best_only=False,\n",
    "                                                         save_freq=\"epoch\", # save every epoch\n",
    "                                                         verbose=1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-04-02T11:21:42.858661820Z"
    }
   },
   "id": "9a4e5c698a5e1f49",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Video NÂ°171: Fitting and evaluating Model 2 (and saving its weights using ModelCheckpoint)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3bca6ff7c0580dad"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Fit model 2 passing in the ModelCheckpoint callbacks"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "872ef31ca80ca47"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Fit the model saving checkpoints every epoch\n",
    "initial_epochs = 5\n",
    "history_10_percent_data_aug = model_2.fit(train_data_10_percent,\n",
    "                                          epochs=initial_epochs,\n",
    "                                          validation_data=test_data,\n",
    "                                          validation_steps=int(0.25 * len(test_data)),\n",
    "                                          callbacks=[create_tensorboard_callback(dir_name=\"transfer_learning\",\n",
    "                                                                                 experiment_name=\"10_percent_data_aug\"),\n",
    "                                                     checkpoint_callback])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-04-02T11:21:42.858858001Z"
    }
   },
   "id": "80d70b2431083637",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# What were model_0 results?\n",
    "model_0.evaluate(test_data)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-04-02T11:21:42.859148351Z"
    }
   },
   "id": "9b07d3371f7c5fb4"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model_2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[17], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# Check model_2 results on all test_data\u001B[39;00m\n\u001B[0;32m----> 2\u001B[0m results_10_percent_data_aug \u001B[38;5;241m=\u001B[39m \u001B[43mmodel_2\u001B[49m\u001B[38;5;241m.\u001B[39mevaluate(test_data)\n\u001B[1;32m      3\u001B[0m results_10_percent_data_aug\n",
      "\u001B[0;31mNameError\u001B[0m: name 'model_2' is not defined"
     ]
    }
   ],
   "source": [
    "# Check model_2 results on all test_data\n",
    "results_10_percent_data_aug = model_2.evaluate(test_data)\n",
    "results_10_percent_data_aug"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-02T12:49:02.883016476Z",
     "start_time": "2024-04-02T12:49:02.802248355Z"
    }
   },
   "id": "2f69c83a17120060",
   "execution_count": 17
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'history_10_percent_data_aug' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[18], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# Plot model loss curves\u001B[39;00m\n\u001B[0;32m----> 2\u001B[0m plot_loss_curves(history\u001B[38;5;241m=\u001B[39m\u001B[43mhistory_10_percent_data_aug\u001B[49m)\n",
      "\u001B[0;31mNameError\u001B[0m: name 'history_10_percent_data_aug' is not defined"
     ]
    }
   ],
   "source": [
    "# Plot model loss curves\n",
    "plot_loss_curves(history=history_10_percent_data_aug)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-02T12:49:06.926690548Z",
     "start_time": "2024-04-02T12:49:06.895635672Z"
    }
   },
   "id": "314eede600779e7a",
   "execution_count": 18
  },
  {
   "cell_type": "markdown",
   "source": [
    "Video NÂ°172: Loading and comparing saved weights to our existing trained Model 2"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b1429a29d7e6ff7d"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Loading in checkpointed weights\n",
    "\n",
    "Loading in checkpointed weights returns a model to a specific checkpoint."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ce6353fe067026b4"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model_2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[19], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# Load in saved model weights and evaluate model\u001B[39;00m\n\u001B[0;32m----> 2\u001B[0m \u001B[43mmodel_2\u001B[49m\u001B[38;5;241m.\u001B[39mload_weights(filepath\u001B[38;5;241m=\u001B[39mcheckpoint_path)\n",
      "\u001B[0;31mNameError\u001B[0m: name 'model_2' is not defined"
     ]
    }
   ],
   "source": [
    "# Load in saved model weights and evaluate model\n",
    "model_2.load_weights(filepath=checkpoint_path)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-02T12:49:09.429205714Z",
     "start_time": "2024-04-02T12:49:09.405444075Z"
    }
   },
   "id": "9398807b91f697b2",
   "execution_count": 19
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model_2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[20], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# Evaluate model_2 with loaded weights\u001B[39;00m\n\u001B[0;32m----> 2\u001B[0m loaded_weights_model_results \u001B[38;5;241m=\u001B[39m \u001B[43mmodel_2\u001B[49m\u001B[38;5;241m.\u001B[39mevaluate(test_data)\n",
      "\u001B[0;31mNameError\u001B[0m: name 'model_2' is not defined"
     ]
    }
   ],
   "source": [
    "# Evaluate model_2 with loaded weights\n",
    "loaded_weights_model_results = model_2.evaluate(test_data)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-02T12:49:11.462976886Z",
     "start_time": "2024-04-02T12:49:11.404124223Z"
    }
   },
   "id": "ee487f10e8a9a5eb",
   "execution_count": 20
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'results_10_percent_data_aug' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[21], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# If the results from our previously evaluated model_2 match the loaded weights, everything has worked!\u001B[39;00m\n\u001B[0;32m----> 2\u001B[0m \u001B[43mresults_10_percent_data_aug\u001B[49m \u001B[38;5;241m==\u001B[39m loaded_weights_model_results\n",
      "\u001B[0;31mNameError\u001B[0m: name 'results_10_percent_data_aug' is not defined"
     ]
    }
   ],
   "source": [
    "# If the results from our previously evaluated model_2 match the loaded weights, everything has worked!\n",
    "results_10_percent_data_aug == loaded_weights_model_results"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-02T12:49:21.036630981Z",
     "start_time": "2024-04-02T12:49:20.984576981Z"
    }
   },
   "id": "1c198092c2b3cf0d",
   "execution_count": 21
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'results_10_percent_data_aug' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[22], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mresults_10_percent_data_aug\u001B[49m\n",
      "\u001B[0;31mNameError\u001B[0m: name 'results_10_percent_data_aug' is not defined"
     ]
    }
   ],
   "source": [
    "results_10_percent_data_aug"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-02T12:49:27.198729973Z",
     "start_time": "2024-04-02T12:49:27.156480361Z"
    }
   },
   "id": "c485b9ff76c3f90d",
   "execution_count": 22
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'loaded_weights_model_results' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[14], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mloaded_weights_model_results\u001B[49m\n",
      "\u001B[0;31mNameError\u001B[0m: name 'loaded_weights_model_results' is not defined"
     ]
    }
   ],
   "source": [
    "loaded_weights_model_results"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-02T12:03:48.138200882Z",
     "start_time": "2024-04-02T12:03:48.103148940Z"
    }
   },
   "id": "8ca15495e53ffdf",
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'results_10_percent_data_aug' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[23], line 3\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# Check to see if loaded model results are very close to our previous non-loaded model results\u001B[39;00m\n\u001B[1;32m      2\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mnumpy\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mnp\u001B[39;00m\n\u001B[0;32m----> 3\u001B[0m np\u001B[38;5;241m.\u001B[39misclose(np\u001B[38;5;241m.\u001B[39marray(\u001B[43mresults_10_percent_data_aug\u001B[49m), np\u001B[38;5;241m.\u001B[39marray(loaded_weights_model_results))\n",
      "\u001B[0;31mNameError\u001B[0m: name 'results_10_percent_data_aug' is not defined"
     ]
    }
   ],
   "source": [
    "# Check to see if loaded model results are very close to our previous non-loaded model results\n",
    "import numpy as np\n",
    "np.isclose(np.array(results_10_percent_data_aug), np.array(loaded_weights_model_results))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-02T12:49:33.273896052Z",
     "start_time": "2024-04-02T12:49:33.241047686Z"
    }
   },
   "id": "ce21953455c361b3",
   "execution_count": 23
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "f35d5340929cf2a5"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
