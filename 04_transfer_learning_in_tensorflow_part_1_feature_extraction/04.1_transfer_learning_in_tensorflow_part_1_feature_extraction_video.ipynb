{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Transfer Learning with TensorFlow Part 1: Feature Extraction\n",
    "\n",
    "Transfer learning is leveraging a working model's existing architecture and learned patterns for our problem.\n",
    "\n",
    "There are two main benefits:\n",
    "1. Can leverage an existing neural network architecture proven to work on problems similar to our own.\n",
    "2. Can leverage a working neural network architecture which has already learned patterns on similar data to our own, then we can adapt those patterns to our own data."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "204a066ad6528067"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Video NÂ°143: Downloading and preparing data for our first transfer learning model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "50dc49d7d0cdbde4"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Download and becoming one with the data"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6dbd197029c01f7b"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from utils.data_acquisition.data_downloader import download_data"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-23T14:52:01.075572951Z",
     "start_time": "2024-03-23T14:52:01.029975704Z"
    }
   },
   "id": "a35a84ebcc5c47b5",
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-03-23T14:52:02.265946520Z",
     "start_time": "2024-03-23T14:52:01.075957935Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The file 10_food_classes_10_percent.zip already exists.\n",
      "Extracting 10_food_classes_10_percent.zip as ZIP...\n",
      "10_food_classes_10_percent.zip has been extracted to current directory.\n"
     ]
    }
   ],
   "source": [
    "# Get data (10% of 10 food classes from Food101) - https://www.kaggle.com/datasets/dansbecker/food-101\n",
    "url = \"https://storage.googleapis.com/ztm_tf_course/food_vision/10_food_classes_10_percent.zip\"\n",
    "file_path = \"10_food_classes_10_percent.zip\"\n",
    "download_data(url=url, file_path=file_path, extract=True)"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 2 directories and 0 images in '10_food_classes_10_percent'.\n",
      "There are 10 directories and 0 images in '10_food_classes_10_percent/train'.\n",
      "There are 0 directories and 75 images in '10_food_classes_10_percent/train/steak'.\n",
      "There are 0 directories and 75 images in '10_food_classes_10_percent/train/sushi'.\n",
      "There are 0 directories and 75 images in '10_food_classes_10_percent/train/ramen'.\n",
      "There are 0 directories and 75 images in '10_food_classes_10_percent/train/grilled_salmon'.\n",
      "There are 0 directories and 75 images in '10_food_classes_10_percent/train/fried_rice'.\n",
      "There are 0 directories and 75 images in '10_food_classes_10_percent/train/chicken_wings'.\n",
      "There are 0 directories and 75 images in '10_food_classes_10_percent/train/hamburger'.\n",
      "There are 0 directories and 75 images in '10_food_classes_10_percent/train/ice_cream'.\n",
      "There are 0 directories and 75 images in '10_food_classes_10_percent/train/pizza'.\n",
      "There are 0 directories and 75 images in '10_food_classes_10_percent/train/chicken_curry'.\n",
      "There are 10 directories and 0 images in '10_food_classes_10_percent/test'.\n",
      "There are 0 directories and 250 images in '10_food_classes_10_percent/test/steak'.\n",
      "There are 0 directories and 250 images in '10_food_classes_10_percent/test/sushi'.\n",
      "There are 0 directories and 250 images in '10_food_classes_10_percent/test/ramen'.\n",
      "There are 0 directories and 250 images in '10_food_classes_10_percent/test/grilled_salmon'.\n",
      "There are 0 directories and 250 images in '10_food_classes_10_percent/test/fried_rice'.\n",
      "There are 0 directories and 250 images in '10_food_classes_10_percent/test/chicken_wings'.\n",
      "There are 0 directories and 250 images in '10_food_classes_10_percent/test/hamburger'.\n",
      "There are 0 directories and 250 images in '10_food_classes_10_percent/test/ice_cream'.\n",
      "There are 0 directories and 250 images in '10_food_classes_10_percent/test/pizza'.\n",
      "There are 0 directories and 250 images in '10_food_classes_10_percent/test/chicken_curry'.\n"
     ]
    }
   ],
   "source": [
    "# How many images in each folder?\n",
    "import os\n",
    "\n",
    "# Walk through 10 percent data directory and list number of files\n",
    "for dirpath, dirnames, filenames in os.walk(\"10_food_classes_10_percent\"):\n",
    "    print(f\"There are {len(dirnames)} directories and {len(filenames)} images in '{dirpath}'.\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-23T14:52:02.268129381Z",
     "start_time": "2024-03-23T14:52:02.265964483Z"
    }
   },
   "id": "dd970fd3149e6542",
   "execution_count": 8
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Creating data loaders (preparing the data)\n",
    "\n",
    "We'll use the `ImageDataGenerator` class to load in our images in batches. "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6ee5eb277bfc8b9b"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training images:\n",
      "Found 750 images belonging to 10 classes.\n",
      "Testing images:\n",
      "Found 2500 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "# Setup data inputs\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_dir = \"10_food_classes_10_percent/train/\"\n",
    "test_dir = \"10_food_classes_10_percent/test/\"\n",
    "\n",
    "flow_from_dir_args = {\n",
    "    \"target_size\": (224, 224),\n",
    "    \"color_mode\": \"rgb\",\n",
    "    \"batch_size\": 32,\n",
    "    \"class_mode\": \"categorical\",\n",
    "    \"shuffle\": True\n",
    "}\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale=1/255.)\n",
    "test_datagen = ImageDataGenerator(rescale=1/255.)\n",
    "\n",
    "print(\"Training images:\")\n",
    "train_data_10_percent = train_datagen.flow_from_directory(directory=train_dir, **flow_from_dir_args)\n",
    "\n",
    "print(\"Testing images:\")\n",
    "test_data = test_datagen.flow_from_directory(directory=test_dir, **flow_from_dir_args)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-23T14:52:02.346577256Z",
     "start_time": "2024-03-23T14:52:02.266550481Z"
    }
   },
   "id": "ad22c217f630f1c9",
   "execution_count": 9
  },
  {
   "cell_type": "markdown",
   "source": [
    "Video NÂ°144: Introducing Callbacks in TensorFlow and making a callback to track our models"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a73ba3dd202f9181"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Setting up callbacks (things to run whilst our model trains)\n",
    "\n",
    "Callbacks are extra functionality you can add to your models to be performed during or after training. Some of the modt popular callbacks:\n",
    "* Tracking experiments with the TensorBoard callback\n",
    "* Model checkpoint with the ModelCheckpoint callback\n",
    "* Stopping a model from training (before it trains too long and overfits) with the EarlyStopping callback"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9265b8712bde45b4"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Create TensorBoard callback (functionized because we need to create a new one for each model)\n",
    "from utils.training_utilities.model_callbacks import create_tensorboard_callback"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-23T14:52:02.347951607Z",
     "start_time": "2024-03-23T14:52:02.345257346Z"
    }
   },
   "id": "e9affd911c48fa28",
   "execution_count": 10
  },
  {
   "cell_type": "markdown",
   "source": [
    "ðŸ”‘ **Note:** You can customize the directory where your TensorBoard logs (model training metrics) get saved to whatever you like. The `log_dir` parameter we've created above is only one option"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "75ef7b82d12ddac7"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Video NÂ°145: Exploring the TensorFlow Hub website for pretrained models"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "51123f88445d54a8"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Creating models using TensorFlow Hub\n",
    "\n",
    "In the past we've used TensorFlow to create our own models layer by layer from scratch.\n",
    "Now we're going to do a similar process, except the majority of our model's layers are going to come frome TensorFlow Hub.\n",
    "We can access pretrained models on: https://tfhub.dev/\n",
    "Browsing the TensorFlow Hub page and sorting for image classification, we found the following feature vector model link:\n",
    "https://tfhub.dev/tensorflow/efficientnet/b0/feature-vector/1"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2f703525c5899262"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Video NÂ°146: Building and compiling a TensorFlow feature extraction model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6e51d3e6f0203266"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Let's compare the following two models\n",
    "resnet_ulr = \"https://tfhub.dev/google/imagenet/resnet_v2_50/feature_vector/4\"\n",
    "\n",
    "efficientnet_ulr = \"https://rfhub.dev/tensorflow/efficientnet/b0/feature_vector/1\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-23T14:54:05.911494468Z",
     "start_time": "2024-03-23T14:54:05.899750683Z"
    }
   },
   "id": "388554b8fb8daccc",
   "execution_count": 18
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Import dependencies\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "from tensorflow.keras import layers"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-23T14:54:06.293402962Z",
     "start_time": "2024-03-23T14:54:06.282918874Z"
    }
   },
   "id": "ef36fee8d894c027",
   "execution_count": 19
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Let's make a create_model() function to create a model from a URL\n",
    "def create_model_from_url(model_url, num_classes, input_shape, activation=\"softmax\"):\n",
    "    \"\"\"\n",
    "    Takes a TensorFlow Hub URL and creates a keras Sequential model with it.\n",
    "    \n",
    "    :param model_url (str): A TensorFlow Hub feature extraction URL.\n",
    "    :param num_classes (int): Number of output neurons in the output layer, should be equal to number of target classes.\n",
    "    :return: An uncompiled Keras Sequential model with model_url as feature extractor layer and Dense output layer with num_classes output neurons.\n",
    "    \"\"\"\n",
    "    # Download the pretrained model and save it as a Keras layer\n",
    "    feature_extractor = hub.KerasLayer(model_url,\n",
    "                                       trainable=False, # freeze the already learned patterns\n",
    "                                       name='feature_extraction_layer',\n",
    "                                       input_shape=input_shape)\n",
    "    \n",
    "    # Create a new model\n",
    "    model = tf.keras.Sequential([\n",
    "        feature_extractor,\n",
    "        layers.Dense(units=num_classes, activation=activation, name=\"output_layer\")\n",
    "    ])\n",
    "    \n",
    "    return model"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-23T14:54:06.639181149Z",
     "start_time": "2024-03-23T14:54:06.632716581Z"
    }
   },
   "id": "966e3123cc157a39",
   "execution_count": 20
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Creating and testing ResNet TensorFlow Hub Feature Extraction model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "298b6d4d3c35bce6"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-23 15:54:11.365162: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-03-23 15:54:11.518693: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-03-23 15:54:11.518889: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-03-23 15:54:11.519471: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-03-23 15:54:11.519822: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-03-23 15:54:11.519976: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-03-23 15:54:11.520120: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-03-23 15:54:11.585355: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-03-23 15:54:11.585521: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-03-23 15:54:11.585658: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-03-23 15:54:11.585759: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5182 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3050, pci bus id: 0000:09:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/wm18vw/Documents/EnvironnementsDevPython/miniconda3/envs/ML-env/lib/python3.9/site-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
      "Instructions for updating:\n",
      "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/wm18vw/Documents/EnvironnementsDevPython/miniconda3/envs/ML-env/lib/python3.9/site-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
      "Instructions for updating:\n",
      "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n"
     ]
    }
   ],
   "source": [
    "# Create Resnet model\n",
    "resnet_model = create_model_from_url(model_url=resnet_ulr,\n",
    "                                     num_classes=train_data_10_percent.num_classes,\n",
    "                                     input_shape=(224, 224, 3))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-23T14:54:13.092263065Z",
     "start_time": "2024-03-23T14:54:07.623680392Z"
    }
   },
   "id": "62c4cfa1ab51161",
   "execution_count": 21
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " feature_extraction_layer (K  (None, 2048)             23564800  \n",
      " erasLayer)                                                      \n",
      "                                                                 \n",
      " output_layer (Dense)        (None, 10)                20490     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 23,585,290\n",
      "Trainable params: 20,490\n",
      "Non-trainable params: 23,564,800\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "resnet_model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-23T14:54:56.947624651Z",
     "start_time": "2024-03-23T14:54:56.903215359Z"
    }
   },
   "id": "269142f0ab8c81f1",
   "execution_count": 22
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "10"
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_10_percent.num_classes"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-23T14:55:51.698427762Z",
     "start_time": "2024-03-23T14:55:51.644715905Z"
    }
   },
   "id": "550637bbc0435bea",
   "execution_count": 23
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "e3f476abccb25045"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
