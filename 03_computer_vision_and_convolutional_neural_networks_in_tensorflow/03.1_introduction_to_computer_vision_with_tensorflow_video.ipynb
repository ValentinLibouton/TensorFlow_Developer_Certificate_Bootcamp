{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Introduction to Convolutional Neural Networks and Computer Vision with\n",
    "\n",
    "Computer vision is the practice of writing algorithms which can discover patterns in visual data. Such as the camera of a self-driving car recognizing the car in front."
   ],
   "metadata": {
    "id": "WCYQOR9K_04w"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Video NÂ°107: Downloading an image dataset for our first Food Vision model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Get the data\n",
    "\n",
    "The images we're working with are from the Food101 dataset (101 different classes of food): https://www.kaggle.com/dansbecker/food-101\n",
    "\n",
    "However we've modified it to only use two classes (pizza ðŸ• & steak ðŸ¥©) using the image data modification notebook: https://github.com/mrdbourke/tensorflow-deep-learning/blob/main/extras/image_data_modification.ipynb\n",
    "\n",
    "> ðŸ”‘ **Note:** We start with a smaller dataset so we can experiment quickly and figure what works (or better yet what doesn't work) before scaling up."
   ],
   "metadata": {
    "id": "lM6rXCioApOF"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "from utils.data_acquisition.data_downloader import download_data\n",
    "url = \"https://storage.googleapis.com/ztm_tf_course/food_vision/pizza_steak.zip\"\n",
    "download_data(url=url, filename=\"pizza_steak.zip\", extract=True)"
   ],
   "metadata": {
    "id": "RzfnC8SnAo4f",
    "ExecuteTime": {
     "end_time": "2024-03-18T09:22:21.939493580Z",
     "start_time": "2024-03-18T09:22:21.564764433Z"
    }
   },
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The file pizza_steak.zip already exists.\n",
      "magic module not available. Unable to determine archive type. Please install python-magic to enable this feature.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_15296/3627828729.py:1: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Video NÂ°108: Becoming One With Data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Inspect the data (become one with it)\n",
    "\n",
    "A very crucial step at the beginning of any machine learning project is becoming one with the data.\n",
    "And for a computer vision project... this usually means visualizing many samples of your data."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: warning: setlocale: LC_ALL: cannot change locale (en_US.UTF-8)\r\n",
      "pizza_steak\r\n"
     ]
    }
   ],
   "source": [
    "!ls pizza_steak"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-18T08:14:27.953037772Z",
     "start_time": "2024-03-18T08:14:27.078350019Z"
    }
   },
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: warning: setlocale: LC_ALL: cannot change locale (en_US.UTF-8)\r\n",
      "ls: cannot access 'pizza_steak/train/': Not a directory\r\n"
     ]
    }
   ],
   "source": [
    "!ls pizza_steak/train/"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-18T08:14:28.804924518Z",
     "start_time": "2024-03-18T08:14:27.947335622Z"
    }
   },
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: warning: setlocale: LC_ALL: cannot change locale (en_US.UTF-8)\r\n",
      "ls: cannot access 'pizza_steak/train/steak': Not a directory\r\n"
     ]
    }
   ],
   "source": [
    "!ls pizza_steak/train/steak"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-18T08:14:29.680066151Z",
     "start_time": "2024-03-18T08:14:28.809084243Z"
    }
   },
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import os\n",
    "# Walk through pizza_steak directory and list number of files\n",
    "for dirpath, dirnames, filenames in os.walk('pizza_steak'):\n",
    "    print(f\"There are {len(dirnames)} directories and {len(filenames)} images in {dirpath}.\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-18T08:14:29.699159034Z",
     "start_time": "2024-03-18T08:14:29.682032732Z"
    }
   },
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: warning: setlocale: LC_ALL: cannot change locale (en_US.UTF-8)\r\n",
      "-rw-r--r-- 1 wm18vw wm18vw 109540975 Dec  6  2021 pizza_steak\r\n"
     ]
    }
   ],
   "source": [
    "!ls -al pizza_steak"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-18T08:14:30.393724905Z",
     "start_time": "2024-03-18T08:14:29.688603788Z"
    }
   },
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "source": [
    "Video NÂ°109: Becoming One With Data Part 2"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "ename": "NotADirectoryError",
     "evalue": "[Errno 20] Not a directory: 'pizza_steak/train/steak'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNotADirectoryError\u001B[0m                        Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[7], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# Another way to find out how many images are in a directory\u001B[39;00m\n\u001B[0;32m----> 2\u001B[0m num_steak_images_train \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlen\u001B[39m(\u001B[43mos\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlistdir\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mpizza_steak/train/steak\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m)\n\u001B[1;32m      3\u001B[0m num_steak_images_train\n",
      "\u001B[0;31mNotADirectoryError\u001B[0m: [Errno 20] Not a directory: 'pizza_steak/train/steak'"
     ]
    }
   ],
   "source": [
    "# Another way to find out how many images are in a directory\n",
    "num_steak_images_train = len(os.listdir('pizza_steak/train/steak'))\n",
    "num_steak_images_train"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-18T08:14:30.613666776Z",
     "start_time": "2024-03-18T08:14:30.395045842Z"
    }
   },
   "execution_count": 7
  },
  {
   "cell_type": "markdown",
   "source": [
    "To visualize our images, first let's get the class names programmatically."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Get the class names programmatically\n",
    "import pathlib\n",
    "import numpy as np\n",
    "data_dir = pathlib.Path(\"pizza_steak/train\")\n",
    "class_names = np.array(sorted([item.name for item in data_dir.glob(\"*\")])) # Created a list of class_names from the subdirectories\n",
    "print(class_names)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-18T08:14:30.934173932Z",
     "start_time": "2024-03-18T08:14:30.617886857Z"
    }
   },
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Let's visualize our images\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import random\n",
    "\n",
    "def view_random_images(target_dir, target_class):\n",
    "    # Setup the target directory (we'll view images from here)\n",
    "    target_folder = os.path.join(target_dir, target_class)\n",
    "    \n",
    "    # Get a random image path\n",
    "    random_image = random.sample(os.listdir(target_folder), 1)\n",
    "    print(random_image)\n",
    "    \n",
    "    # Read in the image and plot it using matplotlib\n",
    "    img = mpimg.imread(os.path.join(target_folder, random_image[0]))\n",
    "    plt.imshow(img)\n",
    "    plt.title(target_class)\n",
    "    plt.axis(\"off\")\n",
    "    \n",
    "    print(f\"Image shape: {img.shape}\") # show the shape of the image\n",
    "    \n",
    "    return img"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-18T08:14:30.620362884Z"
    }
   },
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# View a random image from the training dataset\n",
    "img = view_random_images(target_dir=\"pizza_steak/train/\",\n",
    "                         target_class=\"steak\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-18T08:14:30.622059653Z"
    }
   },
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# The images we've imported and plotted are actually giant arrays/tensors of different pixel values\n",
    "import tensorflow as tf\n",
    "tf.constant(img)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-18T08:14:30.624441615Z"
    }
   },
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Video NÂ°110: Becoming One With Data Part 3"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# View the image shape\n",
    "img.shape # returns width, height, colour channels"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-18T08:14:30.627900870Z"
    }
   },
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "ðŸ”‘ **Note:** As we've discussed before, many machine learning models, including neural networks prefer the values they work with to be between 0 and 1. Knowing this, one of the most common preprocessing steps for working with images is to **scale** (also referred to as **normalize**) their pixel values by dividing the image arrays by 255. (since 255 is the maximum pixel value)."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "img.min(), img.max()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-18T08:14:30.630967798Z"
    }
   },
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Get all the pixel values between 0 & 1 (scale/normalize the data, as neural networks love values between 0 & 1)\n",
    "img/255"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-18T08:14:30.635177568Z"
    }
   },
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Video NÂ°111: Building an end to end CNN Model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## An end-to-end example\n",
    "\n",
    "Let's build a convolutional neural network to find patterns in our images, more specifically we a need way to:\n",
    "* Load our images\n",
    "* Preprocess our images\n",
    "* Build a CNN to find patterns in our images\n",
    "* Compile our CNN\n",
    "* Fit the CNN to our training data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# set the seed\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# Preprocess data (get all of the pixel values between 0 & 1, also called scaling/normalization)\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "valid_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Setup paths to our data directories\n",
    "train_dir = pathlib.Path(\"pizza_steak/train\")\n",
    "test_dir = pathlib.Path(\"pizza_steak/test\")\n",
    "\n",
    "# Import data from directories and turn it into batches\n",
    "train_data = train_datagen.flow_from_directory(directory=train_dir,\n",
    "                                               batch_size=32,\n",
    "                                               target_size=(224, 224),\n",
    "                                               class_mode=\"binary\",\n",
    "                                               seed=42)\n",
    "valid_data = valid_datagen.flow_from_directory(directory=test_dir,\n",
    "                                               batch_size=32,\n",
    "                                               target_size=(224, 224),\n",
    "                                               class_mode=\"binary\",\n",
    "                                               seed=42)\n",
    "\n",
    "# Build a CNN model (same as the Tiny VGG on the CNN explainer website)\n",
    "model_1 = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(filters=10,\n",
    "                           kernel_size=3,\n",
    "                           activation=tf.keras.activations.relu,\n",
    "                           input_shape=(224, 224, 3)),\n",
    "    tf.keras.layers.Conv2D(filters=10,\n",
    "                           kernel_size=3,\n",
    "                           activation=tf.keras.activations.relu),\n",
    "    tf.keras.layers.MaxPooling2D(pool_size=2,\n",
    "                                 padding=\"valid\"),\n",
    "    tf.keras.layers.Conv2D(filters=10,\n",
    "                           kernel_size=3,\n",
    "                           activation=tf.keras.activations.relu),\n",
    "    tf.keras.layers.Conv2D(filters=10,\n",
    "                           kernel_size=3,\n",
    "                           activation=tf.keras.activations.relu),\n",
    "    tf.keras.layers.MaxPooling2D(pool_size=2),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(1, activation=tf.keras.activations.sigmoid)\n",
    "])\n",
    "\n",
    "# Compile our CNN\n",
    "model_1.compile(loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "                optimizer=tf.keras.optimizers.Adam(),\n",
    "                metrics=tf.keras.metrics.BinaryAccuracy())\n",
    "\n",
    "# Fit the model\n",
    "history_1 = model_1.fit(train_data,\n",
    "                        epochs=5,\n",
    "                        steps_per_epoch=len(train_data),\n",
    "                        validation_data=valid_data,\n",
    "                        validation_steps=len(valid_data))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-18T08:14:30.638545191Z"
    }
   },
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Video NÂ°112: Using a GPU to run our CNN model 5x faster"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "> ðŸ”‘ **Note:** If the above cell is taking longer than ~10 seconds per epoch, make sure you're using a GPU."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Get a model summary\n",
    "model_1.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-18T08:14:30.679422601Z"
    }
   },
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "ðŸ›  **Practice/exercise:** Go through the CNN explainer website for a minimum of 10 minutes and compare our neural network with theirs: https://poloclub.github.io/cnn-explainer/"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Video NÂ°113: Trying a non-CNN model on our image data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Using the same model as before\n",
    "\n",
    "Let's replicate the model we've built in a previous section to see if it works with our image data.\n",
    "\n",
    "The model we're building is from the [TensorFlow playground](https://playground.tensorflow.org/#activation=tanh&batchSize=10&dataset=circle&regDataset=reg-plane&learningRate=0.03&regularizationRate=0&noise=0&networkShape=4,2&seed=0.32373&showTestData=false&discretize=false&percTrainData=50&x=true&y=true&xTimesY=false&xSquared=false&ySquared=false&cosX=false&sinX=false&cosY=false&sinY=false&collectStats=false&problem=classification&initZero=false&hideText=false)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "train_data"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-18T08:14:30.679814772Z"
    }
   },
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Set random seed\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# Create a model to replicate the TensorFlow Playground model\n",
    "model_2 = tf.keras.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=(224, 224, 3)),\n",
    "    tf.keras.layers.Dense(4, activation=tf.keras.activations.relu),\n",
    "    tf.keras.layers.Dense(4, activation=tf.keras.activations.relu),\n",
    "    tf.keras.layers.Dense(1, activation=tf.keras.activations.sigmoid)\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model_2.compile(loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "                optimizer=tf.keras.optimizers.Adam(),\n",
    "                metrics=tf.keras.metrics.BinaryAccuracy())\n",
    "\n",
    "# Fir the model\n",
    "model_2.fit(train_data,\n",
    "            epochs=5,\n",
    "            steps_per_epoch=len(train_data),\n",
    "            validation_data=valid_data,\n",
    "            validation_steps=len(valid_data))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-18T08:14:30.680202308Z"
    }
   },
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Video NÂ°114: Improving our non-CNN model by adding more layers"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Get a summary of model_2\n",
    "model_2.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-18T08:14:30.680549368Z"
    }
   },
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Despite having 20x more parameters than our CNN (model_1), model_2 performs terribly... let's try to improve it."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Set the random seed\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# Create the model\n",
    "model_3 = tf.keras.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=(224, 224, 3)),\n",
    "    tf.keras.layers.Dense(100, activation=tf.keras.activations.relu),\n",
    "    tf.keras.layers.Dense(100, activation=tf.keras.activations.relu),\n",
    "    tf.keras.layers.Dense(100, activation=tf.keras.activations.relu),\n",
    "    tf.keras.layers.Dense(1, activation=tf.keras.activations.sigmoid)\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model_3.compile(loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "                optimizer=tf.keras.optimizers.Adam(),\n",
    "                metrics=tf.keras.metrics.BinaryCrossentropy())\n",
    "\n",
    "# Fit the model\n",
    "history_3 = model_3.fit(train_data,\n",
    "                        epochs=5,\n",
    "                        steps_per_epoch=len(train_data),\n",
    "                        validation_data=valid_data,\n",
    "                        validation_steps=len(valid_data))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-18T08:14:30.680840828Z"
    }
   },
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Get a summary of model_3\n",
    "model_3.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-18T08:14:30.681135857Z"
    }
   },
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "15073201/31101"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-18T08:14:30.682071797Z"
    }
   },
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Video NÂ°115: Breaking our CNN model down part 1: Becoming one with the data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "ðŸ”‘ **Note:** You can think of trainable parameters as patterns a model can learn from data. Intuitively, you might think more is better. And in lots of cases, it is. But in this case, the difference here is the two different styles of model we're using. Where a series of dense layers has a number of different learnable parameters connected to each other and hence a higher number of possible learnable patterns, **a convolutional neural network seeks to sort out and learn the most important patterns in an image**.\n",
    "So even though these are less learnable parameters in our convolutional neural network, these are often more helpful in deciphering between different **features** in an image."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "model_1.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-18T08:14:30.682434958Z"
    }
   },
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Binary Classification: Let's break it down\n",
    "\n",
    "1. Become one with the data (visualize, visualize, visualize)\n",
    "2. Preprocess the data (prepared it for our model, the main step here was scaling/normalizing)\n",
    "3. Create a model (start with a baseline)\n",
    "4. Fit the model\n",
    "5. Evaluate the model\n",
    "6. Adjust different parameters and improve the model (try to beat our basline)\n",
    "7. Repeat until satisfied (experiment, experiment, experiment)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1. Become one with the data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Visualize data\n",
    "plt.figure()\n",
    "plt.subplot(1, 2, 1)\n",
    "steak_img = view_random_images(\"pizza_steak/train/\", \"steak\")\n",
    "plt.subplot(1, 2, 2)\n",
    "pizza_img = view_random_images(\"pizza_steak/train/\", \"pizza\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-18T08:14:30.682747590Z"
    }
   },
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Video NÂ°116: Breaking our CNN model down part 2: Preparing to load our data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2. Preprocess the data (prepare it for a model)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Define directory dataset paths\n",
    "train_dir = \"pizza_steak/train/\"\n",
    "test_dir = \"pizza_steak/test/\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-18T08:14:30.683037455Z"
    }
   },
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Our next step is to turn our data into **batches**.\n",
    "\n",
    "A batch is a small subset of data. Rather than look at all ~10000 images at one time, a model might only look at 32 at a time.\n",
    "\n",
    "It does this for a couple of reasons:\n",
    "1. 10000 images (or more) might not fit into the memory of your processor (GPU).\n",
    "2. Trying to learn the patterns in 10000 images in one hit could result in the model not being able to learn very well.\n",
    "\n",
    "Why 32? &rarr; https://arxiv.org/pdf/1804.07612.pdf\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Create train and test data generators and rescale the data\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "train_datagen = ImageDataGenerator(rescale=1/255)\n",
    "test_datagen = ImageDataGenerator(rescale=1/255)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-18T08:14:30.683307687Z"
    }
   },
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Video NÂ°117: Breaking our CNN model down part 3: Loading our data with ImageDataGenerator"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Load in our image data from directories and turn them into batches\n",
    "train_data = train_datagen.flow_from_directory(directory=train_dir, # target directory of images\n",
    "                                               target_size=(224, 224), # target size of images (height, width)\n",
    "                                               class_mode='binary', # type of data you're working with\n",
    "                                               batch_size=32) # size of minibatches to load data into\n",
    "test_data = test_datagen.flow_from_directory(directory=test_dir,\n",
    "                                               target_size=(224, 224),\n",
    "                                               class_mode='binary',\n",
    "                                               batch_size=32)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-18T08:14:30.683570903Z"
    }
   },
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Get a sample of a train data batch\n",
    "images, labels = train_data.next() # get the \"next\" batch of images/labels in train_data\n",
    "len(images), len(labels)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-18T08:14:30.683979376Z"
    }
   },
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# How many batches are there?\n",
    "len(train_data)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-18T08:14:30.687184932Z"
    }
   },
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# We have 1500 images divided into 47 batches of 32 images\n",
    "1500/32"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-18T08:14:30.690689458Z"
    }
   },
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Get the first two images\n",
    "images[:2], images[0].shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-18T08:14:30.694237563Z"
    }
   },
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# images have been resized\n",
    "images[7].shape, images[11].shape, images[16].shape, images[21].shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-18T08:14:30.697446496Z"
    }
   },
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# View the first batch of labels\n",
    "labels"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-18T08:14:30.700799209Z"
    }
   },
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Video NÂ°118: Breaking our CNN model down part 4: Building a baseline CNN model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 3. Create a CNN model (start with a baseline)\n",
    "\n",
    "A basline is a relatively simple model or existing result that you setup when beginning a machine learning experiment and then as you keep experimenting, you try to beat the baseline.\n",
    "\n",
    "> ðŸ”‘ **Note:** In deep learning, there is almost an infinite amount of architectures you could create. So one of the best ways to get started is to start with something simple and see if it works on your data and then introduce complexity as required (e.g. look at which current model is performing best in the field for your problem)."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Make the creating of our model a little easier\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPool2D, Activation\n",
    "from tensorflow.keras import Sequential"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-18T08:14:30.704318290Z"
    }
   },
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Create the model (this will be our baseline, a layer convolutional neural network)\n",
    "model_4 = Sequential([\n",
    "    Conv2D(filters=10, # filter is the number of sliding windows going across an input (higher = more complex model)\n",
    "           kernel_size=3, # or (3, 3) the size of the sliding window going across an input\n",
    "           strides=1, # or (1, 1) the size of the step the sliding window takes across an input\n",
    "           padding=\"valid\", # if \"same\", output shape is same as input shape, if \"valid\", output shape gets compressed\n",
    "           activation=\"relu\",\n",
    "           input_shape=(224, 224, 3)), # input layer (specify input shape)\n",
    "    Conv2D(filters=10, kernel_size=3, activation=\"relu\"),\n",
    "    Conv2D(filters=10, kernel_size=3, activation=\"relu\"),\n",
    "    Flatten(),\n",
    "    Dense(1, activation=\"sigmoid\") # output layer (working with binary classification so only 1 output neuron)\n",
    "])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-18T08:14:30.707508848Z"
    }
   },
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Video NÂ°119: Breaking our CNN model down part 5: Looking inside a Conv2D layer"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "ðŸ›  **Practice:** Understand what's going on in a Conv2D layer by going through the CNN explainer website for 10-20 minutes: [https://poloclub.github.io/cnn-explainer/\n",
    "](https://poloclub.github.io/cnn-explainer/)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Video NÂ°120: Breaking our CNN model down part 6: Compiling and fitting our baseline CNN"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Complie the model\n",
    "model_4.compile(loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "                optimizer=tf.keras.optimizers.Adam(),\n",
    "                metrics=tf.keras.metrics.BinaryAccuracy())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-18T08:14:30.711227110Z"
    }
   },
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Get a summary of our model\n",
    "model_4.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-18T08:14:30.715392520Z"
    }
   },
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "`conv2d_4 (Conv2D)           (None, 222, 222, 10)      280`:\n",
    "Nous avons 222, 222 car nous avons padding=\"valid\" et que input_shape est en 224, 244 ce qui fait que nous perdons les bords.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 4. Fit the model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Check the lengths of training and test data generators\n",
    "len(train_data), len(test_data)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-18T08:14:30.718950068Z"
    }
   },
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Fit the model\n",
    "history_4 = model_4.fit(train_data, # this is a combination of labels and sample data\n",
    "                        epochs=5,\n",
    "                        steps_per_epoch=len(train_data),\n",
    "                        validation_data=test_data,\n",
    "                        validation_steps=len(test_data))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-18T08:14:30.761022697Z"
    }
   },
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Video NÂ°121: Breaking our CNN model down part 7: Evaluating our CNN's training curves"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 5. Evaluating our model\n",
    "\n",
    "It looks like our model is learning something, let's evaluate it."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Let's plot the training curves\n",
    "import pandas as pd\n",
    "pd.DataFrame(history_4.history).plot(figsize=(10, 7))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-18T08:14:30.761509024Z"
    }
   },
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Plot the validation and training curves separatly\n",
    "from utils.data_visualization.model_learning_curves import plot_loss_curves"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-18T08:14:30.761898413Z"
    }
   },
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "ðŸ”‘ **Note:** When a model's **validation loss starts to increase**, it's likely that the model is **overfitting** the training dataset. This means, it's learning the patterns in the training dataset *too well* and thus the model's ability to generalize to unseen data will be diminished."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Check out the loss and accuracy of model_4\n",
    "plot_loss_curves(history_4)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-18T08:14:30.762254606Z"
    }
   },
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "ðŸ”‘ **Note:** Ideally the two loss curves (training and validation) will be very similar to each other decreasing at similar rates), when there are large differences your model may be **overfitting**."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Video NÂ° 122: Breaking our CNN model down part 8: Reducing overfitting with Max Pooling"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 6. Adjust the model parameters\n",
    "\n",
    "Fitting a machine learning model comes in 3 steps:\n",
    "0. Create a baseline\n",
    "1. Beat the baseline by overfitting a larger model\n",
    "2. Reduce overfitting\n",
    "\n",
    "Ways to induce overfitting:\n",
    "* Increase the number of conv layers\n",
    "* Increase the number of conv filters\n",
    "* Add another dense layer to the output of our flattened layer\n",
    "\n",
    "Reduce overfitting:\n",
    "* Add data augmentation\n",
    "* Add regularization layers (such as MaxPool2D)\n",
    "* Add more data...\n",
    "\n",
    "> ðŸ”‘ **Note:** Reducing overfitting is also known as **regularization**."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Create the model (this is going to be our new baseline)\n",
    "model_5 = Sequential([\n",
    "    Conv2D(filters=10, kernel_size=3, activation=\"relu\", input_shape=(224, 224, 3)),\n",
    "    MaxPool2D(pool_size=2),\n",
    "    Conv2D(filters=10, kernel_size=3, activation=\"relu\"),\n",
    "    MaxPool2D(),\n",
    "    Conv2D(filters=10, kernel_size=3, activation=\"relu\"),\n",
    "    MaxPool2D(),\n",
    "    Flatten(),\n",
    "    Dense(1, activation=\"sigmoid\")\n",
    "])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-18T08:14:30.762513872Z"
    }
   },
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "**About `pool_size`:** - Video NÂ°122 @ 6:16<br>\n",
    "Downsample the input representation by taking the max value over the window defined by `pool_size` for each dimension along the features axis."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model_5.compile(loss=\"binary_crossentropy\",\n",
    "                optimizer=Adam(),\n",
    "                metrics=[\"accuracy\"])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-18T08:14:30.762741615Z"
    }
   },
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Fit the model\n",
    "history_5 = model_5.fit(train_data,\n",
    "                        epochs=5,\n",
    "                        steps_per_epoch=len(train_data),\n",
    "                        validation_data=test_data,\n",
    "                        validation_steps=len(test_data))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-18T08:14:30.762952430Z"
    }
   },
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Get a summary of our model with max pooling\n",
    "model_5.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-18T08:14:30.763169988Z"
    }
   },
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Plot loss curves\n",
    "plot_loss_curves(history_5)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-18T08:14:30.763452332Z"
    }
   },
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Video NÂ°123: Breaking our CNN model down part 9: Reducing overfitting with data augmentation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Opening our bag of tricks and finding data augmentation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Create ImageDataGenerator training instance with data augmentation\n",
    "train_datagen_augmented = ImageDataGenerator(rescale=1/255,\n",
    "                                             rotation_range=0.2, # how much do you want to rotate an image?\n",
    "                                             shear_range=0.2, # how much do you want to shear an image?\n",
    "                                             zoom_range=0.2, # zoom in randomly on an image\n",
    "                                             width_shift_range=0.2, # move your image around on the x-axis\n",
    "                                             height_shift_range=0.3, # move your image around on the y-axis\n",
    "                                             horizontal_flip=True) # do you want to flip an image?\n",
    "\n",
    "# Create ImageDataGenerator without data augmentation\n",
    "train_datagen = ImageDataGenerator(rescale=1/255)\n",
    "\n",
    "# Create ImageDataGenerator without data augmentation for the test dataset\n",
    "test_datagen = ImageDataGenerator(rescale=1/255)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-18T08:14:30.763701335Z"
    }
   },
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "> ðŸ¤” **Question:** What is data augmentation?\n",
    "\n",
    "Data augmentation is the process of altering  our training data, leading it to have more diversity and in turn allowing our models to learn more generalizable (hopefully) patterns.\n",
    "Altering might mean adjusting the rotation of an image, flipping it, cropping it or something similar.\n",
    "\n",
    "Let's write some code to visualize data augmentation..."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Video NÂ°124: Breaking our CNN model down part 10: Visualizing our augmentation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "common_args = {\n",
    "    \"target_size\": (224, 224),\n",
    "    \"batch_size\": 32,\n",
    "    \"class_mode\": \"binary\",\n",
    "    \"shuffle\": False  # for demonstration purpose only\n",
    "}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-18T08:14:30.763940002Z"
    }
   },
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# import data and augment it from training directory\n",
    "print(\"Augmented training data:\")\n",
    "train_data_augmented = train_datagen_augmented.flow_from_directory(train_dir, **common_args)\n",
    "\n",
    "# Create non-augmented train data batches\n",
    "print(\"Non-augmented training data:\")\n",
    "train_data = train_datagen.flow_from_directory(train_dir, **common_args)\n",
    "\n",
    "# Create non-augmented test data batches\n",
    "print(\"Non-augmented test data:\")\n",
    "test_data = test_datagen.flow_from_directory(test_dir, **common_args)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-18T08:14:30.764232630Z"
    }
   },
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "ðŸ”‘ **Note:** Data augmentation is usually only performed on the training data. Using `ImageDataGenerator` built-in data augmentation parameters our images are left as they are in the directories but are modified as they're loaded into the model.\n",
    "\n",
    "Finally... let's visualize some augmented data!!!"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Get sample data batches\n",
    "images, labels = train_data.next()\n",
    "augmented_images, augmented_labels = train_data_augmented.next() # note: labels aren't augments... only data (images)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-18T08:14:30.764474179Z"
    }
   },
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Show original image and augmented image\n",
    "from utils.data_visualization.augmentation_effects import plot_original_and_augmented"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-18T08:14:30.764689368Z"
    }
   },
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "plot_original_and_augmented(original_images=images, augmented_images=augmented_images)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-18T08:14:30.765123125Z"
    }
   },
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Video NÂ°125: Breaking our CNN model down part 11: Training a CNN model on augmented data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now we've seen what augmente training data looks like, let's build a model and see how it learns on augmented data."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Create a model (same as model_5)\n",
    "model_6 = Sequential([\n",
    "    Conv2D(filters=10, kernel_size=3, activation=\"relu\"),\n",
    "    MaxPool2D(pool_size=2),\n",
    "    Conv2D(filters=10, kernel_size=3, activation=\"relu\"),\n",
    "    MaxPool2D(),\n",
    "    Conv2D(filters=10, kernel_size=3, activation=\"relu\"),\n",
    "    MaxPool2D(),\n",
    "    Flatten(),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model_6.compile(loss='binary_crossentropy',\n",
    "                optimizer=Adam(),\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "# Fit the model\n",
    "history_6 = model_6.fit(train_data_augmented, # fitting model_6 on augmented training data\n",
    "                        epochs=5,\n",
    "                        steps_per_epoch=len(train_data_augmented),\n",
    "                        validation_data=test_data,\n",
    "                        validation_steps=len(test_data))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-18T08:14:30.765353556Z"
    }
   },
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Check our models training curves\n",
    "plot_loss_curves(history=history_6)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-18T08:14:30.765612260Z"
    }
   },
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Video NÂ°126: Breaking our CNN model down part 12: Discovering the power of shuffling data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let's shuffle our augmented training data and train another model (the same as before) on it and see what happens. "
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "common_args = {\n",
    "    \"target_size\": (224, 224),\n",
    "    \"batch_size\": 32,\n",
    "    \"class_mode\": \"binary\",\n",
    "    \"shuffle\": True\n",
    "}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-18T08:14:30.765834561Z"
    }
   },
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# import data and augment it and shuffle from training directory\n",
    "train_data_augmented_shuffled = train_datagen_augmented.flow_from_directory(train_dir, **common_args)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-18T08:14:30.766063571Z"
    }
   },
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "conv2d_args = {\n",
    "    \"filters\":10,\n",
    "    \"kernel_size\":3,\n",
    "    \"activation\": \"relu\"\n",
    "}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-18T08:14:30.766285260Z"
    }
   },
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Create a model (same as model_5)\n",
    "model_7 = Sequential([\n",
    "    Conv2D(**conv2d_args),\n",
    "    MaxPool2D(pool_size=2),\n",
    "    Conv2D(**conv2d_args),\n",
    "    MaxPool2D(),\n",
    "    Conv2D(**conv2d_args),\n",
    "    MaxPool2D(),\n",
    "    Flatten(),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model_7.compile(loss='binary_crossentropy',\n",
    "                optimizer=Adam(),\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "# Fit the model\n",
    "history_7 = model_7.fit(train_data_augmented_shuffled, # fitting model_6 on augmented training data\n",
    "                        epochs=5,\n",
    "                        steps_per_epoch=len(train_data_augmented_shuffled),\n",
    "                        validation_data=test_data,\n",
    "                        validation_steps=len(test_data))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-18T08:14:30.766500529Z"
    }
   },
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Check our models training curves\n",
    "plot_loss_curves(history=history_7)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-18T08:14:30.766708635Z"
    }
   },
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "ðŸ”‘ **Note:** When shuffling data, the model gets exposed to all different kinds of data during training, thus enabling it to learn features across a wide array of images (in our case, pizza & steak at the same time instead of just pizza then steak)."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Video NÂ°127: Breaking our CNN model down part 13: Exploring options to improve our model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 7. Repeat until satisied\n",
    "\n",
    "Since we've already beaten our baseline, there are a few things we could try to continue to improve our model:\n",
    "\n",
    "* Increase the number of model layers (e.g. add more `Conv2D` / `MaxPool2D` layers)\n",
    "* Increase the number of filters in each convolutional layer (e.g. from 10 to 32 even 64)\n",
    "* Train for longer (more epochs)\n",
    "* Find an ideal learning rate\n",
    "* Get more data (give the model more opportunities to learn)\n",
    "* Use **transfer learning** to leverage what another image model has learn and adjust it for our own use case\n",
    "\n",
    "> ðŸ›  **Practice:** Recreate the model on the CNN explainer website (same as `model_1`) and see how it performs on the augmented shuffled training data."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Video NÂ°128: Downloading a custom image to make predictions on"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Making a prediction with our trained model on our own custom data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Classes we're working with\n",
    "print(class_names)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-18T08:14:30.767036481Z"
    }
   },
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'download_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[1], line 3\u001B[0m\n\u001B[1;32m      1\u001B[0m url \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhttps://github.com/mrdbourke/tensorflow-deep-learning/blob/main/images/03-steak.jpeg?raw=true\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m      2\u001B[0m filename\u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m03-steak.jpeg\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m----> 3\u001B[0m \u001B[43mdownload_data\u001B[49m(url\u001B[38;5;241m=\u001B[39murl, filename\u001B[38;5;241m=\u001B[39mfilename, extract\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n",
      "\u001B[0;31mNameError\u001B[0m: name 'download_data' is not defined"
     ]
    }
   ],
   "source": [
    "url = \"https://github.com/mrdbourke/tensorflow-deep-learning/blob/main/images/03-steak.jpeg?raw=true\"\n",
    "filename= \"03-steak.jpeg\"\n",
    "download_data(url=url, filename=filename, extract=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-18T13:03:36.886056733Z",
     "start_time": "2024-03-18T13:03:36.645678405Z"
    }
   },
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "steak = mpimg.imread(filename)\n",
    "plt.imshow(steak)\n",
    "plt.axis(False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-18T08:14:30.812728982Z"
    }
   },
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Check the shape of our image\n",
    "steak.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-18T08:14:30.813098641Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Video NÂ°129: Writing a helper function to load and preprocessing custom images"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "> ðŸ”‘ **Note:** When you train a neural network and you want to make a prediction with it on your own custom data, it's important than your custom data (or new data) is preprocessed into the same format as the data your model was trained on."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Create a function to import an image and resize it to be able to be used with our model\n",
    "def load_and_prep_image(filename, img_shape=224):\n",
    "    \"\"\"\n",
    "    Reads an image from filename, turns it into a tensor and reshapes it to (img_shape, img_shape, colour_channels).\n",
    "    :param filename: \n",
    "    :param img_shape: \n",
    "    :return:\n",
    "    \"\"\"\n",
    "    # Read in the image\n",
    "    img = tf.io.read_file(filename)\n",
    "    # Decode the read file into a tensor\n",
    "    img = tf.image.decode_image(img)\n",
    "    # Resize the image\n",
    "    img = tf.image.resize(img, size=[img_shape, img_shape])\n",
    "    # Rescale the image (get all values between 0 and 1)\n",
    "    img = img/255\n",
    "    return img"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-18T13:22:59.467349205Z",
     "start_time": "2024-03-18T13:22:59.393283772Z"
    }
   },
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[8], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# Load in and preprocess our custom image\u001B[39;00m\n\u001B[0;32m----> 2\u001B[0m steak \u001B[38;5;241m=\u001B[39m \u001B[43mload_and_prep_image\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43m03-steak.jpeg\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m      3\u001B[0m steak\n",
      "Cell \u001B[0;32mIn[7], line 10\u001B[0m, in \u001B[0;36mload_and_prep_image\u001B[0;34m(filename, img_shape)\u001B[0m\n\u001B[1;32m      3\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m      4\u001B[0m \u001B[38;5;124;03mReads an image from filename, turns it into a tensor and reshapes it to (img_shape, img_shape, colour_channels).\u001B[39;00m\n\u001B[1;32m      5\u001B[0m \u001B[38;5;124;03m:param filename: \u001B[39;00m\n\u001B[1;32m      6\u001B[0m \u001B[38;5;124;03m:param img_shape: \u001B[39;00m\n\u001B[1;32m      7\u001B[0m \u001B[38;5;124;03m:return:\u001B[39;00m\n\u001B[1;32m      8\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m      9\u001B[0m \u001B[38;5;66;03m# Read in the image\u001B[39;00m\n\u001B[0;32m---> 10\u001B[0m img \u001B[38;5;241m=\u001B[39m \u001B[43mtf\u001B[49m\u001B[38;5;241m.\u001B[39mio\u001B[38;5;241m.\u001B[39mread_file(filename)\n\u001B[1;32m     11\u001B[0m \u001B[38;5;66;03m# Decode the read file into a tensor\u001B[39;00m\n\u001B[1;32m     12\u001B[0m img \u001B[38;5;241m=\u001B[39m tf\u001B[38;5;241m.\u001B[39mimage\u001B[38;5;241m.\u001B[39mdecode_image(img)\n",
      "\u001B[0;31mNameError\u001B[0m: name 'tf' is not defined"
     ]
    }
   ],
   "source": [
    "# Load in and preprocess our custom image\n",
    "steak = load_and_prep_image(\"03-steak.jpeg\")\n",
    "steak"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-18T13:25:03.865137837Z",
     "start_time": "2024-03-18T13:25:03.727942716Z"
    }
   },
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model_7' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[10], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mmodel_7\u001B[49m\u001B[38;5;241m.\u001B[39mpredict(tf\u001B[38;5;241m.\u001B[39mexpand_dims(steak, axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m))\n",
      "\u001B[0;31mNameError\u001B[0m: name 'model_7' is not defined"
     ]
    }
   ],
   "source": [
    "model_7.predict(tf.expand_dims(steak, axis=0))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-18T13:26:12.238567748Z",
     "start_time": "2024-03-18T13:26:12.156307627Z"
    }
   },
   "execution_count": 10
  },
  {
   "cell_type": "markdown",
   "source": [
    "Video NÂ°130: Making a prediction on a custom image with our trained CNN"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ]
}
